{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Project Description\n",
    "The problem that we will look at in this project is the Boston house price dataset (This dataset is also used in chapter 3 of our text book).\n",
    "\n",
    "We have download the dataset for free and placed it in the project directory with the filename “housing.csv“. You can also directly download the dataset:\n",
    "\n",
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.data \n",
    "\n",
    "The dataset describes 13 numerical properties of houses in Boston suburbs and is concerned with modeling the price of houses in those suburbs in thousands of dollars. As such, this is a regression predictive modeling problem. Input attributes include things like crime rate, proportion of nonretail business acres, chemical concentrations and more.\n",
    "\n",
    "This is a well-studied problem in machine learning. It is convenient to work with because all of the input and output attributes are numerical and there are 506 instances to work with.\n",
    "\n",
    "Reasonable performance for models evaluated using Mean Squared Error (MSE) are around 20 in squared thousands of dollars (or $4,500 if you take the square root). This is a nice target to aim for with our neural network model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Develop a Baseline Neural Network Model\n",
    "In this step we will create a baseline neural network model for the regression problem.\n",
    "\n",
    "Let’s start off by including all of the functions and objects we will need for this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error_modified = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load our dataset from a file in the local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is in fact not in CSV format, the attributes are instead separated by whitespace. We can load this easily using the pandas library. We can then split the input (X) and output (Y) attributes so that they are easier to model with Keras and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pd.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
    "dataset = dataframe.values\n",
    "#test_data = dataset[:20,]\n",
    "#dataset = dataset[20:,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "#test_x = test_data[:,0:13]\n",
    "#test_y = test_data[:,13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STandarized dataset\n",
    "standarized = StandardScaler()\n",
    "standarized.fit(X)\n",
    "X_standarized = standarized.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41978194,  0.28482986, -1.2879095 , ..., -1.45900038,\n",
       "         0.44105193, -1.0755623 ],\n",
       "       [-0.41733926, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.44105193, -0.49243937],\n",
       "       [-0.41734159, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.39642699, -1.2087274 ],\n",
       "       ...,\n",
       "       [-0.41344658, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.98304761],\n",
       "       [-0.40776407, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.4032249 , -0.86530163],\n",
       "       [-0.41500016, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.66905833]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized data set\n",
    "X_normalized = X/X.max(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.10302306e-05, 1.80000000e-01, 8.32732516e-02, ...,\n",
       "        6.95454545e-01, 1.00000000e+00, 1.31156176e-01],\n",
       "       [3.06936012e-04, 0.00000000e+00, 2.54866619e-01, ...,\n",
       "        8.09090909e-01, 1.00000000e+00, 2.40716355e-01],\n",
       "       [3.06711233e-04, 0.00000000e+00, 2.54866619e-01, ...,\n",
       "        8.09090909e-01, 9.89745528e-01, 1.06136423e-01],\n",
       "       ...,\n",
       "       [6.82879242e-04, 0.00000000e+00, 4.30064888e-01, ...,\n",
       "        9.54545455e-01, 1.00000000e+00, 1.48538320e-01],\n",
       "       [1.23167768e-03, 0.00000000e+00, 4.30064888e-01, ...,\n",
       "        9.54545455e-01, 9.91307634e-01, 1.70661048e-01],\n",
       "       [5.32839119e-04, 0.00000000e+00, 4.30064888e-01, ...,\n",
       "        9.54545455e-01, 1.00000000e+00, 2.07532262e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create Keras models and evaluate them with scikit-learn by using handy wrapper objects provided by the Keras library. This is desirable, because scikit-learn excels at evaluating models and will allow us to use powerful data preparation and model evaluation schemes with very few lines of code.\n",
    "\n",
    "The Keras wrappers require a function as an argument. This function that we must define is responsible for creating the neural network model to be evaluated.\n",
    "\n",
    "Below we define the function to create the baseline model to be evaluated. It is a simple model that has a single fully connected hidden layer with the same number of neurons as input attributes (13). The network uses good practices such as the rectifier activation function for the hidden layer. No activation function is used for the output layer because it is a regression problem and we are interested in predicting numerical values directly without transform.\n",
    "\n",
    "The efficient ADAM optimization algorithm is used and a mean squared error loss function is optimized. This will be the same metric that we will use to evaluate the performance of the model. It is a desirable metric because by taking the square root gives us an error value we can directly understand in the context of the problem (thousands of dollars).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras wrapper object for use in scikit-learn as a regression estimator is called KerasRegressor. We create an instance and pass it both the name of the function to create the neural network model as well as some parameters to pass along to the fit() function of the model later, such as the number of epochs and batch size. Both of these are set to sensible defaults.\n",
    "\n",
    "We also initialize the random number generator with a constant random seed, a process we will repeat for each model evaluated in this tutorial. This is an attempt to ensure we compare models consistently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -32.82 (23.28) MSE\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to evaluate this baseline model. We will use 10-fold cross validation to evaluate the model.Running this code gives us an estimate of the model’s performance on the problem for unseen data. The result reports the mean squared error including the average and standard deviation (average variance) across all 10 folds of the cross validation evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Modeling The Standardized Dataset\n",
    "An important concern with the Boston house price dataset is that the input attributes all vary in their scales because they measure different quantities.\n",
    "\n",
    "It is almost always good practice to prepare your data before modeling it using a neural network model.\n",
    "\n",
    "Continuing on from the above baseline model, we can re-evaluate the same model using a standardized version of the input dataset.\n",
    "\n",
    "We can use scikit-learn’s Pipeline framework to perform the standardization during the model evaluation process, within each fold of the cross validation. This ensures that there is no data leakage from each testset cross validation fold into the training data:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "\n",
    "The code below creates a scikit-learn Pipeline that first standardizes the dataset then creates and evaluates the baseline neural network model.\n",
    "Running the code provides an improved performance over the baseline model without standardized data, dropping the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -29.59 (27.57) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension of Step 3:\n",
    "A further extension of this step is to similarly apply a rescaling to the output variable such as normalizing it to the range of 0-1 and use a Sigmoid or similar activation function on the output layer to narrow output predictions to the same range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -51.91 (37.66) MSE\n"
     ]
    }
   ],
   "source": [
    "def baseline_model_normalized():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13, activation = 'sigmoid', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model_normalized, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X_normalized, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Tune The Neural Network Topology\n",
    "There are many concerns that can be optimized for a neural network model.\n",
    "\n",
    "Perhaps the point of biggest leverage is the structure of the network itself, including the number of layers and the number of neurons in each layer.\n",
    "\n",
    "In this section we will evaluate two additional network topologies in an effort to further improve the performance of the model. We will look at both a deeper and a wider network topology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.1. Evaluate a Deeper Network Topology\n",
    "One way to improve the performance of a neural network is to add more layers. This might allow the model to extract and recombine higher order features embedded in the data.\n",
    "\n",
    "In this step we will evaluate the effect of adding one more hidden layer to the model. This is as easy as defining a new function that will create this deeper model, copied from our baseline model above. We can then insert a new line after the first hidden layer. In this case with about half the number of neurons.\n",
    "\n",
    "\n",
    "Our network topology now looks like:\n",
    "\n",
    "13 inputs -> [13 -> 6] -> 1 output\n",
    "\n",
    "We can evaluate this network topology in the same way as above, whilst also using the standardization of the dataset that above was shown to improve performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -23.04 (27.04) MSE\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "def larger_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(6, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.2. Evaluate a Wider Network Topology\n",
    "Another approach to increasing the representational capability of the model is to create a wider network.\n",
    "\n",
    "In this section we evaluate the effect of keeping a shallow network architecture and nearly doubling the number of neurons in the one hidden layer.\n",
    "\n",
    "Again, all we need to do is define a new function that creates our neural network model. Here, we have increased the number of neurons in the hidden layer compared to the baseline model from 13 to 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -22.81 (29.18) MSE\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "def wider_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(20, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Really Scaling up: developing a model that overfits\n",
    "Once you’ve obtained a model that has statistical power, the question becomes, is your\n",
    "model sufficiently powerful? Does it have enough layers and parameters to properly\n",
    "model the problem at hand? \n",
    "\n",
    "Remember that the universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
    "\n",
    "To figure out how big a model you’ll need, you must develop a model that overfits.\n",
    "This is fairly easy:\n",
    "1.\tAdd layers.\n",
    "2.\tMake the layers bigger.\n",
    "3.\tTrain for more epochs.\n",
    "\n",
    "Always monitor the training loss and validation loss, as well as the training and validation values for any metrics you care about. When you see that the model’s performance on the validation data begins to degrade, you’ve achieved overfitting.\n",
    "\n",
    "The next step is to start regularizing and tuning the model, to get as close as possible to the ideal model that neither underfits nor overfits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 739us/step - loss: 595.1686\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 530.7832\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 396.0766\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 239.5082\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 125.6734\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 71.3354\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 164us/step - loss: 49.7038\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 39.7463\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 34.0692\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 30.7148\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 28.5647\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 27.0690\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 26.0497\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 25.1365\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 24.4850\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 23.8133\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 23.2896\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 22.8244\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 22.3559\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 21.9634\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 21.6003\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 21.1509\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 20.9183\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 20.3954\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 20.0684\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 19.8295\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 19.4762\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 19.1414\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 18.8398\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 18.6289\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 18.3764\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 18.0097\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 17.7971\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 17.4353\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 17.1783\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 16.9277\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 74us/step - loss: 16.7744\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 130us/step - loss: 16.5003\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 16.1841\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 16.0418\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 15.7574\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 15.6254\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 81us/step - loss: 15.3408\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 15.1355\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 14.9586\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 14.7910\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 14.5731\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 14.4798\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 14.2479\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 14.1543\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 13.9833\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 13.7417\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 13.6022\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 13.4591\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 13.3279\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 13.1539\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 13.0425\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 13.0112\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 12.8855\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 12.6240\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 12.5551\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 12.4774\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 12.3407\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 12.3346\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 12.1741\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 80us/step - loss: 12.0042\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 11.9994\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 11.8374\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 100us/step - loss: 11.6884\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 85us/step - loss: 11.6185\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 11.4866\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 11.5403\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 11.2868\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 11.2545\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 11.1762\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 11.1396\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 11.0064\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 10.9595\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 10.9891\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 10.9034\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 90us/step - loss: 10.7582\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 10.7326\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 10.6798\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 10.5616\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 10.6760\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 10.5006\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 10.4203\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 79us/step - loss: 10.4239\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 10.4354\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 92us/step - loss: 10.3350\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 10.2396\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 10.1871\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 10.1793\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 10.1876\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 3.885 - 0s 81us/step - loss: 10.0093\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 10.1179\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 10.1478\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 9.9971\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 9.9524\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 9.9288\n",
      "51/51 [==============================] - 0s 332us/step\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 345us/step - loss: 574.5108\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 501.9375\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 346.6070\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 192.5646\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 107.3146\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 70.1982\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 52.4023\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 42.5392\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 37.0179\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 33.6801\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 45.75 - 0s 109us/step - loss: 31.6481\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 30.1172\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 28.8821\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 27.8094\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 26.9898\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 25.9611\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 25.1827\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 24.4402\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 23.7196\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 23.1708\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 22.5413\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 21.9423\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 21.3054\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 20.8041\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 20.2873\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 19.7578\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 19.2935\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 18.8784\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 18.4466\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 18.0491\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 17.7267\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 17.2727\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 17.1392\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 16.6367\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 16.3395\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 16.1435\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 15.8307\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 15.5375\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 15.3532\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 15.0941\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 14.8142\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 14.6574\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 14.5048\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 14.2708\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 14.1649\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 13.9717\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 13.8157\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 13.6814\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 13.4239\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 115us/step - loss: 13.3247\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 81us/step - loss: 13.1399\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 13.1151\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 13.0023\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 12.8423\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 12.7450\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 119us/step - loss: 12.6988\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 12.5289\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 12.4031\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 12.3564\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 78us/step - loss: 12.2765\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 12.0935\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 12.1642\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 11.9682\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 113us/step - loss: 11.8934\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 11.7911\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 11.8517\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 11.5854\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 11.6261\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 91us/step - loss: 11.6392\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 89us/step - loss: 11.4991\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 11.3718\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 11.2856\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 11.2638\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 11.2266\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 11.2474\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 11.1525\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 11.1529\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 11.1153\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 86us/step - loss: 10.9046\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 10.9059\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 10.8248\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 10.8658\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 10.7249\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 10.7273\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 10.7501\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 10.5985\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 10.5763\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 10.5945\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 10.5684\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 101us/step - loss: 10.5400\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 10.4439\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 10.3849\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 87us/step - loss: 10.4131\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.3787\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 10.3523\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 10.3392\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 10.3711\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 10.2552\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 10.2364\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 10.1796\n",
      "51/51 [==============================] - 0s 404us/step\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 371us/step - loss: 608.5930\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 536.5957\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 394.4656\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 239.9153\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 129.1032\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 70.2925\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 46.0630\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 37.1162\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 33.1517\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 30.9982\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 29.6995\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 28.5894\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 27.8032\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 81us/step - loss: 27.0358\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 122us/step - loss: 26.2957\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 98us/step - loss: 25.5513\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 24.9554\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 24.2099\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 23.7391\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 23.0748\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 22.4088\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 21.7563\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 21.2243\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 20.7283\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 20.0680\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 81us/step - loss: 19.4915\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 18.9840\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 18.3570\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 126us/step - loss: 17.9471\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 17.4408\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 17.1598\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 94us/step - loss: 16.6685\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 16.3735\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 15.9146\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 15.5202\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 15.4203\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 14.7867\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 14.5507\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 14.3151\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 13.9622\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 13.7643\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 13.4645\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 13.2778\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 13.1081\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 12.9026\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 12.7789\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 12.5141\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 12.3610\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 12.3634\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 83us/step - loss: 12.1398\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 11.9909\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 11.8567\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 11.7355\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 11.7180\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 11.6448\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 75us/step - loss: 11.4234\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 11.3382\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 11.3045\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 11.1515\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 11.1679\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 11.0249\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 11.1048\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 73us/step - loss: 10.8883\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 10.8224\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 10.7967\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.7480\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.6994\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.5649\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.6289\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.6140\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 84us/step - loss: 10.5268\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 10.5397\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 117us/step - loss: 10.4288\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 109us/step - loss: 10.4028\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 88us/step - loss: 10.3900\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 96us/step - loss: 10.3824\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 128us/step - loss: 10.3168\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 10.3481\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 10.2715\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 10.2077\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.1429\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.1739\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 10.0673\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.0848\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 105us/step - loss: 10.0816\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 9.9929\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 10.1057\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 9.9584\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 9.9690\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 9.9225\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 9.9037\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 9.9046\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 9.9328\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 9.9142\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 9.8200\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 9.6779\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 103us/step - loss: 9.8779\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 9.8004\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 9.7389\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 9.7549\n",
      "51/51 [==============================] - 0s 593us/step\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 421us/step - loss: 527.2304\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 465.5669\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 320.6032\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 171.3164\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 91.2915\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 59.4821\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 45.1251\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 37.0415\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 32.3291\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 29.4135\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 27.6052\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 120us/step - loss: 26.4127\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 124us/step - loss: 25.3188\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 24.4642\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 23.7588\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 23.0008\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 93us/step - loss: 22.4515\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 21.8688\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 21.2538\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 20.7227\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 20.2228\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 19.6821\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 19.2511\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 95us/step - loss: 18.8404\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 157us/step - loss: 18.3140\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 17.9309\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 17.4566\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 17.0249\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 16.6724\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 16.3199\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 15.9400\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 15.5577\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 15.2482\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 14.8734\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 14.5281\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 14.3287\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 13.8632\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 13.6901\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 13.4567\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 13.0879\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 12.8608\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 12.5926\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 12.3368\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 12.1134\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 12.0202\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 11.7598\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 11.5827\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 11.4010\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 11.3376\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 11.1054\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 11.0367\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 116us/step - loss: 10.8928\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 10.8186\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 123us/step - loss: 10.6538\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 10.6556\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 125us/step - loss: 10.5323\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 10.3588\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 10.3207\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 112us/step - loss: 10.2602\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 121us/step - loss: 10.0690\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 10.1595\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 118us/step - loss: 10.0549\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 10.0063\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 9.8686\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 9.7718\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 9.7314\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 9.7216\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 9.6266\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 9.6703\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 9.5088\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 9.5163\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 9.4843\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 9.4228\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 9.3600\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 9.2799\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 9.2625\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 9.2324\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 158us/step - loss: 9.1945\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 156us/step - loss: 9.1596\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 9.0217\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 9.0000\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 8.9508\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 8.9266\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 8.7875\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 8.6997\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 8.7054\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 8.7559\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 8.6360\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 8.6080\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 8.5592\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 8.5389\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 8.5226\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 8.4747\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 8.4317\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 8.3620\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 8.3706\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 8.2573\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 8.3376\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 8.3091\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 8.2833\n",
      "51/51 [==============================] - 0s 899us/step\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 545us/step - loss: 551.3338\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 484.3029\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 360.7282\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 222.8590\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 153us/step - loss: 122.7800\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 77.3993\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 56.5349\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 44.0056\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 36.5940\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 32.2855\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 29.8876\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 28.3344\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 27.3078\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 26.3868\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 25.6482\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 25.0107\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 24.4149\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 23.7873\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 23.1333\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 176us/step - loss: 22.5030\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 21.9472\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 21.3765\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 20.8270\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 20.2421\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 19.8763\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 19.3231\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 18.9419\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 18.4240\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 18.0650\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 17.6272\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 17.2773\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 16.9683\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 16.5331\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 16.30250s - loss: 16.33\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 15.9970\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 15.6503\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 15.4480\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 15.1072\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 14.8505\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 14.6237\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 14.3814\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 14.1796\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 129us/step - loss: 13.9901\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 13.8473\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 13.6445\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 13.4501\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 114us/step - loss: 13.3331\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 13.1103\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 13.0127\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 12.8664\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 12.7260\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 12.6186\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 12.4939\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 12.3919\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 12.2591\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 12.1777\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 12.0117\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 11.9436\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 11.8240\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 11.7187\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 11.5310\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 11.4960\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 11.3980\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 11.3783\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 176us/step - loss: 11.2839\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 11.1667\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 11.1700\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 11.0532\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 10.9779\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 10.9266\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 10.8505\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 10.7949\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 10.7498\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 142us/step - loss: 10.6810\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 10.7206\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 107us/step - loss: 10.6705\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 166us/step - loss: 10.5531\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 10.5058\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 127us/step - loss: 10.4549\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 10.4412\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 10.3103\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 10.3055\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 10.2448\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 10.2820\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 10.1940\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 10.1071\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 160us/step - loss: 10.1986\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 10.0761\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 10.1050\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 172us/step - loss: 10.0486\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 10.0048\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 9.9669\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 9.9292\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 9.9534\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 9.8713\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 97us/step - loss: 9.9198\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 9.7780\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 9.7981\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 9.7929\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 9.6906\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 526us/step - loss: 528.4162\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 133us/step - loss: 463.3307\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 134us/step - loss: 339.6728\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 102us/step - loss: 201.2446\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 168us/step - loss: 106.0049\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 63.8818\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 45.9356\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 131us/step - loss: 36.8751\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 106us/step - loss: 32.4062\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 180us/step - loss: 29.9719\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 28.3434\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 27.2010\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 26.1369\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 176us/step - loss: 25.2927\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 24.6629\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 23.8518\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 23.2574\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 22.6793\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 22.2173\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 148us/step - loss: 21.6974\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 150us/step - loss: 21.0196\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 20.5652\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 20.1148\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 108us/step - loss: 19.6254\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 176us/step - loss: 19.1939\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 18.8065\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 18.3761\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 18.0756\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 179us/step - loss: 17.5698\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 17.1769\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 16.8238\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 152us/step - loss: 16.4606\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 16.0934\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 15.8731\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 15.5859\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 15.2905\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 14.9955\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 14.7013\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 14.4956\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 14.1738\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 13.9891\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 13.7751\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 13.6124\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 13.3794\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 13.1637\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 13.0373\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 143us/step - loss: 12.8887\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 12.7191\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 12.5639\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 12.5251\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 12.2547\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 149us/step - loss: 12.2187\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 12.0526\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 110us/step - loss: 11.9658\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 181us/step - loss: 11.9564\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 11.7682\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 11.6948\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 11.5129\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 11.5804\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 11.4358\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 147us/step - loss: 11.2855\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 11.3470\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 105us/step - loss: 11.1766\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 11.0307\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 11.0835\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 151us/step - loss: 10.9467\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 111us/step - loss: 10.9522\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 173us/step - loss: 10.8763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 10.8660\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 142us/step - loss: 10.6938\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 145us/step - loss: 10.7761\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 10.7036\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 10.6143\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 139us/step - loss: 10.5321\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 99us/step - loss: 10.5554\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 10.4305\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 10.4059\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 10.4621\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 10.2496\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 146us/step - loss: 10.2842\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 10.2053\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 144us/step - loss: 10.2226\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 136us/step - loss: 10.1724\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 132us/step - loss: 10.1481\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 10.0789\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 135us/step - loss: 10.0526\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 137us/step - loss: 10.0455\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 10.0905\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 10.1224\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 101us/step - loss: 9.8518\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 169us/step - loss: 9.9183\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 9.8721\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 9.8449\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 9.7708\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 104us/step - loss: 9.7583\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 170us/step - loss: 9.7981\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 9.7114\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 141us/step - loss: 9.6629\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 138us/step - loss: 9.5791\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 140us/step - loss: 9.5257\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "456/456 [==============================] - 0s 504us/step - loss: 589.4007\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 167us/step - loss: 512.4122\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 133us/step - loss: 355.7852\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 104us/step - loss: 197.6819\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 103.8258\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 63.7924\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 47.3710\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 38.9304\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 34.2680\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 31.4260\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 29.6631\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 28.4366\n",
      "Epoch 13/100\n",
      "456/456 [==============================] - 0s 168us/step - loss: 27.2447\n",
      "Epoch 14/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 26.4092\n",
      "Epoch 15/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 25.5372\n",
      "Epoch 16/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 24.9106\n",
      "Epoch 17/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 24.2098\n",
      "Epoch 18/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 23.6031\n",
      "Epoch 19/100\n",
      "456/456 [==============================] - 0s 112us/step - loss: 23.0672\n",
      "Epoch 20/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 22.5288\n",
      "Epoch 21/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 21.9928\n",
      "Epoch 22/100\n",
      "456/456 [==============================] - 0s 152us/step - loss: 21.5498\n",
      "Epoch 23/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 21.0241\n",
      "Epoch 24/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 20.6873\n",
      "Epoch 25/100\n",
      "456/456 [==============================] - 0s 139us/step - loss: 20.1644\n",
      "Epoch 26/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 19.8189\n",
      "Epoch 27/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 19.3656\n",
      "Epoch 28/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 18.9535\n",
      "Epoch 29/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 18.7173\n",
      "Epoch 30/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 18.2512\n",
      "Epoch 31/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 18.0873\n",
      "Epoch 32/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 17.5131\n",
      "Epoch 33/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 17.2341\n",
      "Epoch 34/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 16.8656\n",
      "Epoch 35/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 16.5591\n",
      "Epoch 36/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 16.3015\n",
      "Epoch 37/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 15.9593\n",
      "Epoch 38/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 15.6707\n",
      "Epoch 39/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 15.4450\n",
      "Epoch 40/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 15.1653\n",
      "Epoch 41/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 14.8794\n",
      "Epoch 42/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 14.6394\n",
      "Epoch 43/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 14.4706\n",
      "Epoch 44/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 14.2398\n",
      "Epoch 45/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 13.8936\n",
      "Epoch 46/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 13.8709\n",
      "Epoch 47/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 13.5891\n",
      "Epoch 48/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 13.3964\n",
      "Epoch 49/100\n",
      "456/456 [==============================] - 0s 143us/step - loss: 13.2134\n",
      "Epoch 50/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 13.0830\n",
      "Epoch 51/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 12.9871\n",
      "Epoch 52/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 12.8076\n",
      "Epoch 53/100\n",
      "456/456 [==============================] - 0s 143us/step - loss: 12.6571\n",
      "Epoch 54/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 12.5523\n",
      "Epoch 55/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 12.4678\n",
      "Epoch 56/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 12.2605\n",
      "Epoch 57/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 12.1502\n",
      "Epoch 58/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 12.0842\n",
      "Epoch 59/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 11.9180\n",
      "Epoch 60/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 11.8101\n",
      "Epoch 61/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 11.7798\n",
      "Epoch 62/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 11.7493\n",
      "Epoch 63/100\n",
      "456/456 [==============================] - 0s 177us/step - loss: 11.7081\n",
      "Epoch 64/100\n",
      "456/456 [==============================] - 0s 163us/step - loss: 11.6527\n",
      "Epoch 65/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 11.5070\n",
      "Epoch 66/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 11.3477\n",
      "Epoch 67/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 11.4147\n",
      "Epoch 68/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 11.2555\n",
      "Epoch 69/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 11.2768\n",
      "Epoch 70/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 11.1715\n",
      "Epoch 71/100\n",
      "456/456 [==============================] - 0s 101us/step - loss: 11.1697\n",
      "Epoch 72/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 11.0079\n",
      "Epoch 73/100\n",
      "456/456 [==============================] - 0s 110us/step - loss: 10.9784\n",
      "Epoch 74/100\n",
      "456/456 [==============================] - 0s 175us/step - loss: 10.9986\n",
      "Epoch 75/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 10.8839\n",
      "Epoch 76/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 10.9933\n",
      "Epoch 77/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 10.8600\n",
      "Epoch 78/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.9881\n",
      "Epoch 79/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 10.7399\n",
      "Epoch 80/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 10.6859\n",
      "Epoch 81/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.7130\n",
      "Epoch 82/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 10.6476\n",
      "Epoch 83/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.6465\n",
      "Epoch 84/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 10.5692\n",
      "Epoch 85/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 10.5096\n",
      "Epoch 86/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.5030\n",
      "Epoch 87/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 10.4690\n",
      "Epoch 88/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 10.3682\n",
      "Epoch 89/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 10.4804\n",
      "Epoch 90/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 10.4874\n",
      "Epoch 91/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 10.3401\n",
      "Epoch 92/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 10.3019\n",
      "Epoch 93/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.3083\n",
      "Epoch 94/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.2536\n",
      "Epoch 95/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.2541\n",
      "Epoch 96/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.1874\n",
      "Epoch 97/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.1702\n",
      "Epoch 98/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 10.1649\n",
      "Epoch 99/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.2147\n",
      "Epoch 100/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 10.0920\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "456/456 [==============================] - 0s 590us/step - loss: 591.1259\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 138us/step - loss: 509.4209\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 136us/step - loss: 353.1989\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 133us/step - loss: 192.0841\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 95.3019\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 55.8070\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 38.0179\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 29.7418\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 26.2059\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 24.4871\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 23.4539\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 22.6948\n",
      "Epoch 13/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 21.9353\n",
      "Epoch 14/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 21.2660\n",
      "Epoch 15/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 20.6695\n",
      "Epoch 16/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 20.1658\n",
      "Epoch 17/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 19.5318\n",
      "Epoch 18/100\n",
      "456/456 [==============================] - 0s 156us/step - loss: 18.9739\n",
      "Epoch 19/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 18.4851\n",
      "Epoch 20/100\n",
      "456/456 [==============================] - 0s 154us/step - loss: 17.9884\n",
      "Epoch 21/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 17.5678\n",
      "Epoch 22/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 17.1018\n",
      "Epoch 23/100\n",
      "456/456 [==============================] - 0s 161us/step - loss: 16.7456\n",
      "Epoch 24/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 16.2212\n",
      "Epoch 25/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 15.8543\n",
      "Epoch 26/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 15.2839\n",
      "Epoch 27/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 14.9348\n",
      "Epoch 28/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 14.5203\n",
      "Epoch 29/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 14.0724\n",
      "Epoch 30/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 13.6433\n",
      "Epoch 31/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 13.2300\n",
      "Epoch 32/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 12.8013\n",
      "Epoch 33/100\n",
      "456/456 [==============================] - 0s 150us/step - loss: 12.3921\n",
      "Epoch 34/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 12.0350\n",
      "Epoch 35/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 11.6920\n",
      "Epoch 36/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 11.3270\n",
      "Epoch 37/100\n",
      "456/456 [==============================] - 0s 159us/step - loss: 10.9725\n",
      "Epoch 38/100\n",
      "456/456 [==============================] - 0s 143us/step - loss: 10.6799\n",
      "Epoch 39/100\n",
      "456/456 [==============================] - 0s 136us/step - loss: 10.3651\n",
      "Epoch 40/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 10.0988\n",
      "Epoch 41/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 9.8320\n",
      "Epoch 42/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 9.6292\n",
      "Epoch 43/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 9.3707\n",
      "Epoch 44/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 9.1338\n",
      "Epoch 45/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 8.9205\n",
      "Epoch 46/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 8.7841\n",
      "Epoch 47/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 8.5659\n",
      "Epoch 48/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 8.4153\n",
      "Epoch 49/100\n",
      "456/456 [==============================] - 0s 156us/step - loss: 8.3402\n",
      "Epoch 50/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 8.1657\n",
      "Epoch 51/100\n",
      "456/456 [==============================] - 0s 168us/step - loss: 7.9812\n",
      "Epoch 52/100\n",
      "456/456 [==============================] - 0s 168us/step - loss: 7.8288\n",
      "Epoch 53/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 7.7332\n",
      "Epoch 54/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 7.6137\n",
      "Epoch 55/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 7.5669\n",
      "Epoch 56/100\n",
      "456/456 [==============================] - 0s 173us/step - loss: 7.3858\n",
      "Epoch 57/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 7.3322\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 0s 157us/step - loss: 7.2671\n",
      "Epoch 59/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 7.1677\n",
      "Epoch 60/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 7.0378\n",
      "Epoch 61/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 7.0314\n",
      "Epoch 62/100\n",
      "456/456 [==============================] - 0s 143us/step - loss: 6.9246\n",
      "Epoch 63/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 6.9233\n",
      "Epoch 64/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 6.8661\n",
      "Epoch 65/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 6.7681\n",
      "Epoch 66/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 6.7720\n",
      "Epoch 67/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 6.7275\n",
      "Epoch 68/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 6.5684\n",
      "Epoch 69/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 6.7062\n",
      "Epoch 70/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 6.5791\n",
      "Epoch 71/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 6.5004\n",
      "Epoch 72/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 6.5303\n",
      "Epoch 73/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 6.4787\n",
      "Epoch 74/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 6.4363\n",
      "Epoch 75/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 6.3968\n",
      "Epoch 76/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 6.3156\n",
      "Epoch 77/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 6.3532\n",
      "Epoch 78/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 6.2401\n",
      "Epoch 79/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 6.2232\n",
      "Epoch 80/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 6.2433\n",
      "Epoch 81/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 6.2005\n",
      "Epoch 82/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 6.1570\n",
      "Epoch 83/100\n",
      "456/456 [==============================] - 0s 164us/step - loss: 6.0331\n",
      "Epoch 84/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 6.2458\n",
      "Epoch 85/100\n",
      "456/456 [==============================] - 0s 164us/step - loss: 6.0593\n",
      "Epoch 86/100\n",
      "456/456 [==============================] - 0s 164us/step - loss: 6.0338\n",
      "Epoch 87/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 5.9965\n",
      "Epoch 88/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 6.0010\n",
      "Epoch 89/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 5.9968\n",
      "Epoch 90/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 6.0351\n",
      "Epoch 91/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 5.9167\n",
      "Epoch 92/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 5.9189\n",
      "Epoch 93/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 5.8886\n",
      "Epoch 94/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 5.9309\n",
      "Epoch 95/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 5.8933\n",
      "Epoch 96/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 5.8439\n",
      "Epoch 97/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 5.8472\n",
      "Epoch 98/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 5.8449\n",
      "Epoch 99/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 5.8153\n",
      "Epoch 100/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 5.7606\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "456/456 [==============================] - 0s 651us/step - loss: 619.9546\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 138us/step - loss: 538.9912\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 380.9012\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 221.8210\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 124.3502\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 78.1036\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 56.2894\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 45.1321\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 39.3345\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 35.9137\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 33.7321\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 32.1596\n",
      "Epoch 13/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 30.8682\n",
      "Epoch 14/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 29.7752\n",
      "Epoch 15/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 28.6669\n",
      "Epoch 16/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 27.7173\n",
      "Epoch 17/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 26.8310\n",
      "Epoch 18/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 26.0176\n",
      "Epoch 19/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 25.3096\n",
      "Epoch 20/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 24.4951\n",
      "Epoch 21/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 23.8852\n",
      "Epoch 22/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 23.2720\n",
      "Epoch 23/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 22.6184\n",
      "Epoch 24/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 22.0080\n",
      "Epoch 25/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 21.3910\n",
      "Epoch 26/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 20.9220\n",
      "Epoch 27/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 20.4822\n",
      "Epoch 28/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 19.9473\n",
      "Epoch 29/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 19.4176\n",
      "Epoch 30/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 19.0668\n",
      "Epoch 31/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 18.6333\n",
      "Epoch 32/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 18.2433\n",
      "Epoch 33/100\n",
      "456/456 [==============================] - 0s 152us/step - loss: 17.7625\n",
      "Epoch 34/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 17.4612\n",
      "Epoch 35/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 17.1335\n",
      "Epoch 36/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 16.6668\n",
      "Epoch 37/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 16.3178\n",
      "Epoch 38/100\n",
      "456/456 [==============================] - 0s 154us/step - loss: 16.0586\n",
      "Epoch 39/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 15.6618\n",
      "Epoch 40/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 15.3580\n",
      "Epoch 41/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 15.0735\n",
      "Epoch 42/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 14.7474\n",
      "Epoch 43/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 14.4863\n",
      "Epoch 44/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 14.2273\n",
      "Epoch 45/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 14.0302\n",
      "Epoch 46/100\n",
      "456/456 [==============================] - 0s 168us/step - loss: 13.8079\n",
      "Epoch 47/100\n",
      "456/456 [==============================] - 0s 159us/step - loss: 13.5731\n",
      "Epoch 48/100\n",
      "456/456 [==============================] - 0s 164us/step - loss: 13.4930\n",
      "Epoch 49/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 13.2344\n",
      "Epoch 50/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 13.1136\n",
      "Epoch 51/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 12.8868\n",
      "Epoch 52/100\n",
      "456/456 [==============================] - 0s 110us/step - loss: 12.7230\n",
      "Epoch 53/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 12.5708\n",
      "Epoch 54/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 12.4506\n",
      "Epoch 55/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 12.2553\n",
      "Epoch 56/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 12.1631\n",
      "Epoch 57/100\n",
      "456/456 [==============================] - 0s 143us/step - loss: 12.1148\n",
      "Epoch 58/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 11.8600\n",
      "Epoch 59/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 11.7830\n",
      "Epoch 60/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 11.6945\n",
      "Epoch 61/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 11.5911\n",
      "Epoch 62/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 11.3881\n",
      "Epoch 63/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 11.3973\n",
      "Epoch 64/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 11.2413\n",
      "Epoch 65/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 11.1846\n",
      "Epoch 66/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 11.1528\n",
      "Epoch 67/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 10.9386\n",
      "Epoch 68/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.9327\n",
      "Epoch 69/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 10.8531\n",
      "Epoch 70/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 10.7104\n",
      "Epoch 71/100\n",
      "456/456 [==============================] - 0s 140us/step - loss: 10.6811\n",
      "Epoch 72/100\n",
      "456/456 [==============================] - 0s 143us/step - loss: 10.6485\n",
      "Epoch 73/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.5160\n",
      "Epoch 74/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 10.3959\n",
      "Epoch 75/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.3142\n",
      "Epoch 76/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 10.2829\n",
      "Epoch 77/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 10.1605\n",
      "Epoch 78/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 10.1724\n",
      "Epoch 79/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 10.0769\n",
      "Epoch 80/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 9.9512\n",
      "Epoch 81/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 9.9297\n",
      "Epoch 82/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 9.8518\n",
      "Epoch 83/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 9.9241\n",
      "Epoch 84/100\n",
      "456/456 [==============================] - 0s 141us/step - loss: 9.7650\n",
      "Epoch 85/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 9.7075\n",
      "Epoch 86/100\n",
      "456/456 [==============================] - 0s 144us/step - loss: 9.6669\n",
      "Epoch 87/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 9.6005\n",
      "Epoch 88/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 9.6451\n",
      "Epoch 89/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 9.5444\n",
      "Epoch 90/100\n",
      "456/456 [==============================] - 0s 145us/step - loss: 9.4867\n",
      "Epoch 91/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 9.4625\n",
      "Epoch 92/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 9.3988\n",
      "Epoch 93/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 9.4432\n",
      "Epoch 94/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 9.3194\n",
      "Epoch 95/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 9.3871\n",
      "Epoch 96/100\n",
      "456/456 [==============================] - 0s 168us/step - loss: 9.2594\n",
      "Epoch 97/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 9.2534\n",
      "Epoch 98/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 9.1903\n",
      "Epoch 99/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 9.1225\n",
      "Epoch 100/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 9.1470\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "456/456 [==============================] - 0s 668us/step - loss: 603.9847\n",
      "Epoch 2/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 529.4981\n",
      "Epoch 3/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 378.5819\n",
      "Epoch 4/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 220.6609\n",
      "Epoch 5/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 111.7595\n",
      "Epoch 6/100\n",
      "456/456 [==============================] - 0s 156us/step - loss: 61.7832\n",
      "Epoch 7/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 42.2131\n",
      "Epoch 8/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 34.1754\n",
      "Epoch 9/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 30.4033\n",
      "Epoch 10/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 28.3760\n",
      "Epoch 11/100\n",
      "456/456 [==============================] - 0s 167us/step - loss: 27.1619\n",
      "Epoch 12/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 26.2828\n",
      "Epoch 13/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 25.6173\n",
      "Epoch 14/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 25.0527\n",
      "Epoch 15/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 24.5252\n",
      "Epoch 16/100\n",
      "456/456 [==============================] - 0s 159us/step - loss: 24.0285\n",
      "Epoch 17/100\n",
      "456/456 [==============================] - 0s 156us/step - loss: 23.5835\n",
      "Epoch 18/100\n",
      "456/456 [==============================] - 0s 158us/step - loss: 23.2499\n",
      "Epoch 19/100\n",
      "456/456 [==============================] - 0s 161us/step - loss: 22.7577\n",
      "Epoch 20/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 22.3744\n",
      "Epoch 21/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 22.0208\n",
      "Epoch 22/100\n",
      "456/456 [==============================] - 0s 164us/step - loss: 21.6704\n",
      "Epoch 23/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 21.3014\n",
      "Epoch 24/100\n",
      "456/456 [==============================] - 0s 152us/step - loss: 20.9109\n",
      "Epoch 25/100\n",
      "456/456 [==============================] - 0s 156us/step - loss: 20.6869\n",
      "Epoch 26/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 20.2390\n",
      "Epoch 27/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 19.8725\n",
      "Epoch 28/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 19.5563\n",
      "Epoch 29/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 19.1706\n",
      "Epoch 30/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 18.8332\n",
      "Epoch 31/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 18.5738\n",
      "Epoch 32/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 18.3897\n",
      "Epoch 33/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 18.0257\n",
      "Epoch 34/100\n",
      "456/456 [==============================] - 0s 154us/step - loss: 17.6530\n",
      "Epoch 35/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 17.4061\n",
      "Epoch 36/100\n",
      "456/456 [==============================] - 0s 171us/step - loss: 17.2375\n",
      "Epoch 37/100\n",
      "456/456 [==============================] - 0s 162us/step - loss: 16.9078\n",
      "Epoch 38/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 16.5496\n",
      "Epoch 39/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 16.3949\n",
      "Epoch 40/100\n",
      "456/456 [==============================] - 0s 173us/step - loss: 16.0692\n",
      "Epoch 41/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 15.8304\n",
      "Epoch 42/100\n",
      "456/456 [==============================] - 0s 164us/step - loss: 15.6334\n",
      "Epoch 43/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 15.3176\n",
      "Epoch 44/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 15.1203\n",
      "Epoch 45/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 14.9619\n",
      "Epoch 46/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 14.7318\n",
      "Epoch 47/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 14.4849\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 0s 158us/step - loss: 14.2011\n",
      "Epoch 49/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 14.0393\n",
      "Epoch 50/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 13.8960\n",
      "Epoch 51/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 13.5975\n",
      "Epoch 52/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 13.5714\n",
      "Epoch 53/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 13.4160\n",
      "Epoch 54/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 13.1465\n",
      "Epoch 55/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 12.9686\n",
      "Epoch 56/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 12.8566\n",
      "Epoch 57/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 12.7388\n",
      "Epoch 58/100\n",
      "456/456 [==============================] - 0s 142us/step - loss: 12.5541\n",
      "Epoch 59/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 12.4035\n",
      "Epoch 60/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 12.3118\n",
      "Epoch 61/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 12.1639\n",
      "Epoch 62/100\n",
      "456/456 [==============================] - 0s 148us/step - loss: 12.0325\n",
      "Epoch 63/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 11.9225\n",
      "Epoch 64/100\n",
      "456/456 [==============================] - 0s 146us/step - loss: 11.9451\n",
      "Epoch 65/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 11.7000\n",
      "Epoch 66/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 11.6566\n",
      "Epoch 67/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 11.5675\n",
      "Epoch 68/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 11.3088\n",
      "Epoch 69/100\n",
      "456/456 [==============================] - 0s 152us/step - loss: 11.2411\n",
      "Epoch 70/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 11.1521\n",
      "Epoch 71/100\n",
      "456/456 [==============================] - 0s 158us/step - loss: 11.0608\n",
      "Epoch 72/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 10.9547\n",
      "Epoch 73/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 10.8074\n",
      "Epoch 74/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 10.8056\n",
      "Epoch 75/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 10.7007\n",
      "Epoch 76/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 10.6492\n",
      "Epoch 77/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 10.4422\n",
      "Epoch 78/100\n",
      "456/456 [==============================] - 0s 161us/step - loss: 10.4553\n",
      "Epoch 79/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 10.3671\n",
      "Epoch 80/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 10.2446\n",
      "Epoch 81/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 10.2742\n",
      "Epoch 82/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 10.1295\n",
      "Epoch 83/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 10.0334\n",
      "Epoch 84/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 10.0290\n",
      "Epoch 85/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 9.9239\n",
      "Epoch 86/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 9.8605\n",
      "Epoch 87/100\n",
      "456/456 [==============================] - 0s 149us/step - loss: 9.7355\n",
      "Epoch 88/100\n",
      "456/456 [==============================] - 0s 154us/step - loss: 9.7651\n",
      "Epoch 89/100\n",
      "456/456 [==============================] - 0s 151us/step - loss: 9.7489\n",
      "Epoch 90/100\n",
      "456/456 [==============================] - 0s 155us/step - loss: 9.7078\n",
      "Epoch 91/100\n",
      "456/456 [==============================] - 0s 147us/step - loss: 9.6281\n",
      "Epoch 92/100\n",
      "456/456 [==============================] - 0s 152us/step - loss: 9.5329\n",
      "Epoch 93/100\n",
      "456/456 [==============================] - 0s 166us/step - loss: 9.4353\n",
      "Epoch 94/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 9.4036\n",
      "Epoch 95/100\n",
      "456/456 [==============================] - 0s 160us/step - loss: 9.3797\n",
      "Epoch 96/100\n",
      "456/456 [==============================] - 0s 154us/step - loss: 9.3099\n",
      "Epoch 97/100\n",
      "456/456 [==============================] - 0s 173us/step - loss: 9.3519\n",
      "Epoch 98/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 9.2505\n",
      "Epoch 99/100\n",
      "456/456 [==============================] - 0s 157us/step - loss: 9.2272\n",
      "Epoch 100/100\n",
      "456/456 [==============================] - 0s 153us/step - loss: 9.1354\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "Larger: -22.22 (24.15) MSE\n"
     ]
    }
   ],
   "source": [
    "# model with a more neurons\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -22.28 (22.63) MSE\n"
     ]
    }
   ],
   "source": [
    "# model with a more neurons\n",
    "def model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(30, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model2, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since performance started to degrade so going with model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Tuning the Model\n",
    "With further tuning of aspects like the optimization algorithm etc. and the number of training epochs, it is expected that further improvements are possible. What is the best score that you can achieve on this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.94 (24.39) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -22.52 (25.72) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop and weight drop of 20%\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -23.58 (25.82) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop and weight drop of 30%\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -27.27 (30.01) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop and weight drop of 50%\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -26.97 (29.64) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop and weight regularizer\n",
    "from keras import regularizers\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal',\n",
    "                           kernel_regularizer = regularizers.l1(0.001),\n",
    "                           input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since droping weight is not producing good results so using wieght regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -27.07 (29.93) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop and weight regularizer l1\n",
    "from keras import regularizers\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal',\n",
    "                           kernel_regularizer = regularizers.l1(0.001),\n",
    "                           input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -26.60 (29.87) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop and weight regularizer l2\n",
    "from keras import regularizers\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal',\n",
    "                           kernel_regularizer = regularizers.l2(0.001),\n",
    "                           input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -21.82 (27.15) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop and weight drop of 20%\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=150, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 with rmsprop with 110 epochs\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.99 (25.98) MSE\n"
     ]
    }
   ],
   "source": [
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -22.55 (27.71) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 150 epochs\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=150, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -21.26 (26.61) MSE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model1 with rmsprop with 130 epochs\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=130, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -21.41 (26.81) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 120 epochs\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=120, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -21.16 (25.63) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 115 epochs\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=115, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -22.15 (28.91) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 112 epochs\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=112, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.52 (23.56) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs and second layer of 10 neurons\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(10, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.62 (25.30) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs and second layer of 13 neurons\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(13, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.33 (24.75) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs and second layer of 7 neurons\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(7, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.74 (25.62) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs and second layer of 5 neurons\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(5, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -29.45 (34.63) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs and second layer of 7 neurons and second layer with 3 neurons\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(7, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(3, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 11ms/step - loss: 423.4692\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 62.3609\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 36.0764\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 28.8702\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 25.5660\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 23.4617\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 21.8758\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 20.5043\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 19.7998\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 18.5868\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 17.9350\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 17.2447\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 16.5813\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.8148\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.3878\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.9677\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.4670\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.0208\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.0711\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.7549\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.0904\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.8115\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.7862\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.6123\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.9016\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 12.2640\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.0998\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6574\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5555\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8144\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5668\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1976\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3224\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3060\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1606\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1337\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1834\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3007\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0846\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1101\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1256\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8344\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5596\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9263\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8932\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7577\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9122\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8180\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3970\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5953\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5372\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4306\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5487\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1582\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3128\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1300\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2745\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2466\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2225\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2415\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0558\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1823\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3024\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1255\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9862\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8627\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7296\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1020\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0398\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9096\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0499\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9993\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.9233\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0314\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8194\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9400\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7084\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 9.9528\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.6172\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9615\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7468\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9167\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7083\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3377\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4314\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7716\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7139\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5132\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4603\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3643\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5650\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.6688\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7166\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5938\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5482\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7324\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5542\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.2761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4764\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4119\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3769\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.1168\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.1232\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3250\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3871\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.1520\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3408\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.2673\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.1001\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.1155\n",
      "51/51 [==============================] - 2s 44ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 6s 13ms/step - loss: 440.7685\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 66.0526\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 36.0174\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 29.3065\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 25.8445\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 23.6600\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 22.0763\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 20.7300\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 19.1149\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 18.3751\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 17.4123\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 16.5074\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.9683\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.6213\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.7510\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.6894\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.2242\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.7326\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.4685\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.5251\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.1948\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.1940\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.5185\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.8044\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.6072\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.4145\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.2567\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.2121\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.1671\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.2467\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.3437\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7701\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.9339\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6920\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8550\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7895\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6128\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7662\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5160\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5481\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3526\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3768\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5073\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4332\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5083\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3288\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0549\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4001\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1555\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4268\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9858\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1691\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1417\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3153\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1501\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7148\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0405\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0925\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8370\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0687\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9709\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8850\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8570\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 10.6717\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.7932\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8365\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3466\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9011\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6864\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7869\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5876\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6357\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3818\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6913\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5339\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6393\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5459: 0s -\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4870\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5379\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0982\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.6537\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3945\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.3836\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3230\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3381\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2906\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9951\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0422\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3555\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3627\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2044\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4484\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6534\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4093\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2041\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1833\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2270\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1317\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3503\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2477\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9117\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 10.1801\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9232\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1704\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3163\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0838\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0555\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0899\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.6848\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1345\n",
      "51/51 [==============================] - 2s 45ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 6s 14ms/step - loss: 473.4833\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 67.1858\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 36.6875\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 30.7600\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 27.5464\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 26.1732\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 24.1865\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 23.0750\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 22.0162\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 20.3436\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 18.7678\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 17.3373\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 17.1381\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.9271\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.7094\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.4254\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.8406\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.5587\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.0518\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.7794\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 13.8216\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.3971\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.9958\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.3070\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.9620\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.8152\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.8450\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.1234\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.5269\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.1510\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.1289\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.2932\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.0771\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5212\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.0329\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7919\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8744\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6993\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8690\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7240\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5982\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4392\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1723\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4576\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3853\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0528\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0522\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0972\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.2243\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.2256\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9434\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1874\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1227\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9705\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8952\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8368\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7528\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9583\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6374\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8677\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6512\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6548\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8933\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7204\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5174\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 10.8409\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3447\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5834\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6485\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5708\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7048\n",
      "Epoch 72/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4782\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6341\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5748\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6557\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4427\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4669\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2237\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4587\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3920\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3856\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3992\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4829\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3720\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2989\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1753\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2330\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1204\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3255\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.1649\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2810\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2321\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1828\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2268\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1120\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0821\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2733\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1622A: \n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0545\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2663\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1383\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1551\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9392\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9575\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9132\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0244\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9673\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.6666\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9495\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8638\n",
      "51/51 [==============================] - 2s 42ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 6s 14ms/step - loss: 378.4144\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 56.1857\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 35.1900\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 28.6388\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 25.7079\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 23.6703\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 21.6116\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 20.2364\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 18.6373\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 17.6234\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 16.7408\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.8092\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.8557\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.4608\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.8693\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.4453\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.5547\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.2461\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.8546\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.6481\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.5601\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.1358\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.9039\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6095\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.9389\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6355\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1902\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5282\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4107\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.2265\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.2546\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3953\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0038\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 11.1317\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.8244\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.8180\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9077\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8053\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5254\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7119\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5036\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.4234\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4683\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5854\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5594\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4269\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3909\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4969\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3150\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 10.3537\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4347\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0667\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9519\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8916\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8741\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1503\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3012\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8874\n",
      "Epoch 59/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9119\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9235\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9858\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9031\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8441\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.6669\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8943\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4481\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3877\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5895\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4487\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3908\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5186\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4537\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.2949\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4281\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5189\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4205\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.5307\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3292\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.2368\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.3797\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.1634\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.0490\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 9.2145\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 9.2754\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.1241\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.8887\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.9840\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.7649\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.7226\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.9389\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - ETA: 0s - loss: 8.653 - 1s 3ms/step - loss: 8.9904\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.9199\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.5741\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.9022\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.6727\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.5967\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.6859\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.7529\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.4620\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.6487\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.5565\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.7041\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.5207\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.3641\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.5016\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.3111\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.3351\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.2902\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.0727\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 8.3076\n",
      "51/51 [==============================] - 2s 42ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 6s 13ms/step - loss: 458.2860\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 84.5520\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 40.2313\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 30.8036\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 26.2185\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 23.4797\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 22.0083\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 20.7587\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 19.6107\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 18.9195\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 17.5242\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 17.0628\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 16.1596\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.4007\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 15.2460\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.8147\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.4544\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 14.1882\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.5381\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.6376\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.3263\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.2517\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 13.0971\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.9002\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.4724\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.7424\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.3801\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.3974\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.4781\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.6148\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8961\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.3243\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8219\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.1727\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.9858\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.9548\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7353\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6658\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8185\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7685\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5165\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8933\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8890\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8554\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.8701\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7132\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7009\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5948\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3609\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3815\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.2127\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3316\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4002\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.4435\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1153\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.3649\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0592\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1790\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1695\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1634\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1652\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1190\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8809\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.2707\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0587\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0477\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9714\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9412\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9971\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6932\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7459\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3338\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9581: 0\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9477\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7298\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6540\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5689\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5306\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4991\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5381\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6135\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4530\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1551\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2936\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5087\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4168\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2098\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3500\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0847\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1659\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2424\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9750\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.1083\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.8645\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.0522\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.9158\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2534\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9979\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8007\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7626\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7577\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.6684\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.6814\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 9.8024\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7343\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 9.3992\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 9.6747\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9459\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8292\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.4700\n",
      "51/51 [==============================] - 2s 43ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 7s 16ms/step - loss: 366.7432\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 61.4652\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 40.1809\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 30.3253\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 25.4386\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 23.0903\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 21.0118\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 20.4203\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 18.6439\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 17.6965\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 16.9775\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 16.2362\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 15.4862\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 15.2532\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 14.9322\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 14.2886\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 14.2829\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 13.7900\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 13.4342\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 13.3263\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 1s 2ms/step - loss: 13.1026\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.3774\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 12.6575\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 2s 5ms/step - loss: 12.4775\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 12.5381\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 12.3649\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.9768\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 12.1783\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.8378\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.9898\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.9068\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.4756\n",
      "Epoch 33/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 2s 3ms/step - loss: 11.5938\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.7341\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5748\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.5928\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.6664\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.4924\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 11.5115\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 11.4114\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 11.2736\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1230\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 11.2256\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.0238\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.7037\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1374\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.1502\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0844\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 11.0909\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 11.2743\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.8827\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7271\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.2033\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7371\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 11.0244\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7720\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9624\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6315\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.9070\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6666\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4092\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6966\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.6160\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.7047\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5484\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4772\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2601\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3393\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1970\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5725\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3830\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5706\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4261\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.5418\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.4633\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3947\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2915\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1898\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.2770\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3601\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1570\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 10.1910\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9406\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.3367\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0071\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1766\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8175\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8532\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9058\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8794\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9904\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0968\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0616\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9885\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 10.0100\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9414\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 9.9992\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 10.0402\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.8943\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9541\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9049\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8170\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.7857\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.9327\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 9.8476\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.7512\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0259\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 2s 3ms/step - loss: 9.5465\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.0502\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 1s 3ms/step - loss: 10.1936\n",
      "51/51 [==============================] - 2s 47ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 6s 14ms/step - loss: 427.2395\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 54.4298\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 35.4790\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 29.3094\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 26.4525\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 24.1378\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 22.6548\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 21.2997\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 20.2610\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 18.8340\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 17.5271\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 17.0770\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 15.9896\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 15.7654\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 15.4292\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 15.0382\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 14.7307\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 14.2741\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 14.2888\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 13.5601\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 13.5822\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 13.0246\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.9305\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 13.0311\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 12.8575\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 12.4806\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.5342\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.5102\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.2562\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.1339\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.2759\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.1530\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.1989\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.9793\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.8326\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.0815\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.6837\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.2831\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.4947\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.3244\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.4387\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.2834\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.2862\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.2393\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.3411\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.1933\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.3969\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.0425\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.1788\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.0772\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.7968\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.7259\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.9427\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.8457\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5332\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.6114\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.7482\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.4981\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5837\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5367\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.3869\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.3045\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 10.4515\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5136\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.3762\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - ETA: 0s - loss: 9.333 - 1s 3ms/step - loss: 10.2606\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.1476\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.0267\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.1668\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 10.1665\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.9687\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.9612\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.8700\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.9266\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8047\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6374\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.7045\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6915\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8887\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8217\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6449\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8735\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8012\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.7424\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6545\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6848\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6778\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.4838\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.5636\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3240\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.6397\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6230\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6105\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6322\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6364\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.5390\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.4473\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.4275\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2452\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.5605\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3605\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.4608\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2868\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3765\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1756\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.5111\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2505\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.7701\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2136\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.1725\n",
      "50/50 [==============================] - 2s 46ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 6s 14ms/step - loss: 486.7977\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 82.2474\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 32.9096\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 24.6010\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 20.5319\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 18.1100\n",
      "Epoch 7/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 1s 3ms/step - loss: 16.4568\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 15.7788\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 14.9006\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 14.0060\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 13.1821\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.1454\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.5447\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.1937\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.6554\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8969\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.7988\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.0761\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.8257\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 8.5133\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 8.2169\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 7.9088\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 7.7003\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 7.3490\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 7.3972\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 7.1551\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.8559\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.8232\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.7263\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.6327\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.7114\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.4899\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.5495\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.4461\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.2601\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.3526\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.1532\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.2170\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.2725\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.0552\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.0578\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.0745\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.9929\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.9388\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 6.0333\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.9493\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.7667\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.9141\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.7410\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 5.8198\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 5.8511\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 5.8278\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.8257\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.8885\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.7439\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6748\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.7736\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.7480\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6067\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6895\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.7396\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6579\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6028\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6544\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.7265\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6782\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6980\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6104\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.6158\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.5574\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 5.5926\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 5.5091\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4571\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4668\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4767\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.5287\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4568\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4460\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4349\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4262\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.2873\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3875\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3617\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.4492\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3719\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3889\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3671\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 5.3319\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3711\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3465\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3230\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.2463\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.1742\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3379\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.2853\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3050\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.2396\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 5.2437\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 5.3104\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.2531\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.1811\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 5.1684\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.1112\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.3476\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.0703\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.1253\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.1788\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.1164\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.1470\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 5.2677\n",
      "50/50 [==============================] - 2s 46ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 6s 14ms/step - loss: 456.4097\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 75.5077\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 40.0041\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 32.2407\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 27.6507\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 24.3942\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 22.0747\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 20.7326\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 19.3020\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 18.8205\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 18.0033\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 17.0092\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 16.4659\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 15.8893\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 15.6073\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 15.0951\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 14.6877\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 14.1292\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 13.5209\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 13.6600\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 13.2650\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.9802\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 13.0613\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.7341\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 12.4428\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.2610\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.2654\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 11.5139\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 11.9356\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 11.5161\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 11.5695\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.5843\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.3221: 0s - loss:\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.3922\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 11.2586\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.3315\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.0723\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.1930\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.1177\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 10.9792\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.7923\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.4821\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.2537\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.9834\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.6472\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5194\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.3829\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.4774\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5702\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5495\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.5756\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 10.3287\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 10.3521\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.3439\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.1264\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.9267\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.1125\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.1984\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.1810\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.5728\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.0354\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8921\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.5358\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8667\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.7798\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 9.6325\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.9367\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.6872\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.8398\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.3927\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.6882\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.4994\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.7558\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.4494\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.7741\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.5223\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.8913\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.6294\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.6533\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.6365\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.8051\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.6867\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.4825\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.4406\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.4928\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.2003\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.7011\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.4097\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.1763\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.4286\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.5817\n",
      "Epoch 92/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3237\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2126\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3905\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1329\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1362\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1785\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1884\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.3988\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2949\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3759\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.4444\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.2719\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2754\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.0214\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.2658\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3416\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.2944\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3039\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1577\n",
      "50/50 [==============================] - 2s 47ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 7s 15ms/step - loss: 501.4284\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 88.7150\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 41.8127\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 32.3886\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 28.5195\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 26.2916\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 24.7250\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 23.5648\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 22.0537\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 20.9590\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 20.3203\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 19.1354\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 18.0671\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 17.9475\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 17.2627\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 16.4486\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 15.8312\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 15.1384\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 14.9076\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 14.5306\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 13.9391\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 13.5883\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 13.3856\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.9769\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.8742\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.6582\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.4149\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.2620\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 12.0051\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 11.5600\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.7240\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.7445\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 11.3950\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.5839\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.1066\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.1009\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 11.0557\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.0541\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.8411\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 11.0569\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 10.7820\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 10.6832: 0s -\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 10.6742\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.4642\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 10.3907\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 10.5889\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.3408\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.2291\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8128\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.1568\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.0469\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 10.0912\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.9789\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.9957\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.9923\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.9366\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.7187\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.6738\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.5588\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.9325\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.7470\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6500\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.8296\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.5534\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.5832\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.5562\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 9.4490\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.3723\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6210\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 9.4386\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.6818\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3728\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.3019\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 9.3997\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 3s 6ms/step - loss: 9.2736\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 9.4333\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 9.3864\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1620\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1874\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.0805\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1913\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.3485\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.0442\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1331\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1400\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 8.9493\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.0980\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1348\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.1244\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.0249\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.0476\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 8.9952\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.0868\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 8.9873\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 9.1084\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 1s 3ms/step - loss: 9.0117\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.8821\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.9704\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.6163\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 8.9040\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 8.8431\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.9135\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 3s 6ms/step - loss: 8.7136\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.7923\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 8.8458\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 8.8079\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 2s 5ms/step - loss: 8.8166\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.9166\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.5029\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 8.5234\n",
      "50/50 [==============================] - 3s 50ms/step\n",
      "Larger: -26.68 (33.99) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs, and second layer of 7 neurons, changing batch size to 1\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(7, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=1, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 10ms/step - loss: 601.1684\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 480us/step - loss: 573.9994\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 516.1603\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 427.7817\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 319.2419\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 362us/step - loss: 206.1201\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 121.3474\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 519us/step - loss: 78.4065\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 438us/step - loss: 59.4899\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 453us/step - loss: 47.0909\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 550us/step - loss: 39.1886\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 33.9613\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 30.91950s - loss: 28.\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 449us/step - loss: 29.1110\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 27.6679\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 384us/step - loss: 26.6238\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 357us/step - loss: 25.5952\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 357us/step - loss: 25.0567\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 24.2591\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 346us/step - loss: 23.6038\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 22.7316\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 22.4022\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 397us/step - loss: 21.9198\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 467us/step - loss: 21.4151\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 438us/step - loss: 20.7851\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 441us/step - loss: 20.5426\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 406us/step - loss: 20.1208\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 375us/step - loss: 19.5786\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 19.4687\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 704us/step - loss: 18.9785\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 408us/step - loss: 18.7011\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 430us/step - loss: 18.2779\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 17.7793\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 502us/step - loss: 17.7902\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 454us/step - loss: 17.4163\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 401us/step - loss: 17.0340\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 462us/step - loss: 16.7284\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 563us/step - loss: 16.5134\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 430us/step - loss: 16.1837\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 15.8941\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 421us/step - loss: 15.6047\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 403us/step - loss: 15.3867\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 406us/step - loss: 15.0832\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 368us/step - loss: 14.9311\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 373us/step - loss: 14.7057\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 351us/step - loss: 14.3964\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 14.1559\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 349us/step - loss: 13.9285\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 443us/step - loss: 13.5345\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 449us/step - loss: 13.4529\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 392us/step - loss: 13.2050\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 364us/step - loss: 13.0525\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 397us/step - loss: 12.7843\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 381us/step - loss: 12.6243\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 12.4178\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 423us/step - loss: 12.2336\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 419us/step - loss: 12.0806\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 392us/step - loss: 12.0524\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 373us/step - loss: 11.7837\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 401us/step - loss: 11.8398\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 390us/step - loss: 11.4945\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 373us/step - loss: 11.5888 0s - loss: 11.\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 447us/step - loss: 11.4479\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 462us/step - loss: 11.3133\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 346us/step - loss: 11.2026\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 425us/step - loss: 11.0706\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 473us/step - loss: 10.9410\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 434us/step - loss: 10.9700\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 351us/step - loss: 10.9183\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 392us/step - loss: 10.8237\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 421us/step - loss: 10.8171\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 511us/step - loss: 10.6692\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 375us/step - loss: 10.6225\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 397us/step - loss: 10.6205\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 375us/step - loss: 10.5160\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 513us/step - loss: 10.4667\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 500us/step - loss: 10.2804\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 642us/step - loss: 10.2601\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 408us/step - loss: 10.0392\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 10.1933\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 10.1011\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 561us/step - loss: 10.1284\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 9.9445\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 475us/step - loss: 9.8818\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 463us/step - loss: 9.8734\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 9.8470\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 388us/step - loss: 9.9103\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 377us/step - loss: 9.8107\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 360us/step - loss: 9.7639\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 9.6513\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 370us/step - loss: 9.7120\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 349us/step - loss: 9.8105\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 9.6034\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 9.6209\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 399us/step - loss: 9.5712\n",
      "Epoch 96/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 530us/step - loss: 9.6639\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 590us/step - loss: 9.4847\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 586us/step - loss: 9.5191\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 487us/step - loss: 9.5015\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 581us/step - loss: 9.4832\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 509us/step - loss: 9.3777\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 612us/step - loss: 9.3909\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 438us/step - loss: 9.2213\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 515us/step - loss: 9.4056\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 545us/step - loss: 9.3128\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 433us/step - loss: 9.2387\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 401us/step - loss: 9.3153\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 9.1690\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 458us/step - loss: 9.2298\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 460us/step - loss: 9.2629\n",
      "51/51 [==============================] - 3s 52ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 12ms/step - loss: 584.4121\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 562.4142\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 515.0573\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 442.1606\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 342.3220\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 237.4790\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 147.0389\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 336us/step - loss: 92.2558\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 67.7678\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 367us/step - loss: 54.3151\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 404us/step - loss: 44.9501\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 454us/step - loss: 38.1349\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 414us/step - loss: 34.2202\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 397us/step - loss: 31.9916\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 30.2558\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 435us/step - loss: 28.8836\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 359us/step - loss: 27.8088\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 373us/step - loss: 26.8832\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 427us/step - loss: 25.9524\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 339us/step - loss: 25.1671\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 24.4068\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 432us/step - loss: 23.7579\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 23.1425\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 22.6902\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 22.1164\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 423us/step - loss: 21.6256\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 411us/step - loss: 21.0854\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 426us/step - loss: 20.6118\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 384us/step - loss: 20.2721\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 443us/step - loss: 19.9171\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 19.5579\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 19.1062\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 18.7899\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 18.4932\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 18.1638\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 17.6827\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 17.4840\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 17.1748\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 16.8765\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 16.5951\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 16.3807\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 16.0820\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 15.8199\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 15.5663\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 313us/step - loss: 15.3743\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 15.0228\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 14.8638\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 14.6746\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 353us/step - loss: 14.4927\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 14.3189\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 14.0994\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 313us/step - loss: 13.9343\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 13.8524\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 13.6446\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 13.5047\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 13.2511\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 13.3135\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 13.0781\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 370us/step - loss: 13.0153\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 368us/step - loss: 12.8920\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 359us/step - loss: 12.8283\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 12.5704\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 12.5813\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 12.5339\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 12.3854\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 381us/step - loss: 12.2841\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 339us/step - loss: 12.2577\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 12.1450\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 12.1129\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 345us/step - loss: 12.0098\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.9643\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 312us/step - loss: 11.8527\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 11.7869\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.7217\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 11.6327\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 326us/step - loss: 11.6147\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 341us/step - loss: 11.5783\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 11.5470\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 11.4186\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 11.1859\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 11.2902\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 339us/step - loss: 11.2533\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 11.1937\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 11.1888\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 313us/step - loss: 11.2065\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 11.0996\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 10.9911\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 10.9943\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 325us/step - loss: 11.0055\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 10.9726\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.8715\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 10.8504\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 417us/step - loss: 10.8800\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 408us/step - loss: 10.7285\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 10.6776\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 10.6791\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 10.6325\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 10.5881\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 334us/step - loss: 10.6351\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 10.5607\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.4968\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.5371\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 339us/step - loss: 10.4524\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.4616\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.3944\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 10.2755\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 345us/step - loss: 10.3116\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 321us/step - loss: 10.2670\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 10.3101\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 386us/step - loss: 10.2945\n",
      "51/51 [==============================] - 2s 43ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 11ms/step - loss: 616.3176\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 592.6053\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 537.7503\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 446.4524\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 331.2441\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 210.4218\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 123.3069\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 80.9674\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 61.1016\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 48.9427\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 41.2699\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 321us/step - loss: 36.4531\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 34.1437\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 32.1611\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 30.7464\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 29.7105\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 28.7217\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 27.7647\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 26.8793\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 26.0871\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 25.2732\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 24.6389\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 23.9033\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 23.2256\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 22.4008\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 21.7799\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 21.3749\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 20.8219\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 20.2744\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 19.9083\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 355us/step - loss: 19.3170\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 399us/step - loss: 19.0551\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 397us/step - loss: 18.5690\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 337us/step - loss: 18.1638\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 17.7980\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 332us/step - loss: 17.4056\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 17.1103\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 377us/step - loss: 16.6775\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 16.3852\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 16.0440\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 15.7257\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 15.3986\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 15.0451\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 15.0038\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 14.9138\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 308us/step - loss: 14.4193\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 14.3350\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 14.1391\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 13.9962\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 13.8322\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 325us/step - loss: 13.6845\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 332us/step - loss: 13.5836\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 13.3187\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 13.1109\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 13.1166\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 12.9060\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 12.7778\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 12.7631\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 12.4521\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 325us/step - loss: 12.4198\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 325us/step - loss: 12.2108\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 321us/step - loss: 12.2415\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 336us/step - loss: 12.1821\n",
      "Epoch 64/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 331us/step - loss: 12.0641\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 393us/step - loss: 11.9867\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 416us/step - loss: 11.9160\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 11.6929\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 11.7248\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 11.7554\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 11.5720\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.6605\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 11.5416\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 11.4723\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 11.4014\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 11.3030\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 11.2995\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 11.2195\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 11.1594\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 11.1165\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 11.1191\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 11.0216\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.9331\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 11.0230\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 10.9307\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 10.8480\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 10.8381\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 10.7873\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 10.7923\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.7014\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 10.7183\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 10.7266\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.6688\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 10.6224\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 326us/step - loss: 10.6576\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.5334\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 326us/step - loss: 10.5316\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.6178\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 430us/step - loss: 10.5485\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 401us/step - loss: 10.5462\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 337us/step - loss: 10.4393\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 10.4576\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 325us/step - loss: 10.4418\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 10.4822\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 10.3832\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.2906\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 10.3158\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 10.3133\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 408us/step - loss: 10.3053\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 441us/step - loss: 10.3186\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.1900\n",
      "51/51 [==============================] - 2s 44ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 11ms/step - loss: 533.1887\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 509.5069\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 455.9122\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 416us/step - loss: 370.0995\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 397us/step - loss: 262.6658\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 355us/step - loss: 161.7032\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 97.6609\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 341us/step - loss: 69.4252\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 341us/step - loss: 55.7998\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 46.4676\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 40.3409\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 36.2841\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 362us/step - loss: 33.8590\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 32.1654\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 30.6813\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 29.5589\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 28.5924\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 326us/step - loss: 27.5041\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 341us/step - loss: 26.4416\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 25.6282\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 24.8403\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 24.0644\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 23.2667\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 22.6525\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 22.0261\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 349us/step - loss: 21.4025\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 20.6886\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 341us/step - loss: 20.2820\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 332us/step - loss: 19.9023\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 19.4137\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 18.9330\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 18.4464\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 17.9124\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 17.4877\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 17.2261\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 405us/step - loss: 16.8664\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 438us/step - loss: 16.4482\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 395us/step - loss: 16.0429\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 15.7594\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 15.5493\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 15.2123\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 14.8987\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 351us/step - loss: 14.7293\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 14.4895\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 14.2186\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 337us/step - loss: 13.9985\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 330us/step - loss: 13.8068\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 13.7119\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 13.4296\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 410us/step - loss: 13.2941\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 349us/step - loss: 13.1493\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 359us/step - loss: 13.0170\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 12.8792\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 12.5973\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 334us/step - loss: 12.6514\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 12.4361\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 12.4456\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 336us/step - loss: 12.2365\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 12.0553\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 12.1305\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.9881\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 11.8320\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.7495\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 11.6901\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 11.5649\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.3472\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 310us/step - loss: 11.3885\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 386us/step - loss: 11.3370\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 414us/step - loss: 11.3122\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 390us/step - loss: 11.1509\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 11.1005\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 11.0735\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.9055\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.9561\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.8793\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 10.8430\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 313us/step - loss: 10.7658\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 10.6983\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 10.6025\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 10.6285\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.5597\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 10.4184\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.5553\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 10.3901\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.4392\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.2877\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.2846\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.1649\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.1071\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.2131\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 10.1337\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 10.0958\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 10.0424\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 10.0156\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 9.9965\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 9.8404\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 9.8867\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 9.8950\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 9.7410\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 9.8191\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 370us/step - loss: 9.7263\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 381us/step - loss: 9.7172\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 379us/step - loss: 9.6355\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 9.6896\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 368us/step - loss: 9.6469\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 9.6646\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 355us/step - loss: 9.5776\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 9.5419\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 9.3031\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 9.5240\n",
      "51/51 [==============================] - 2s 46ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 6s 12ms/step - loss: 561.5198\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 546.6653\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 443us/step - loss: 509.6948\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 395us/step - loss: 448.4876\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 368us/step - loss: 365.4005\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 269.1248\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 176.7981\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 108.6254\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 288us/step - loss: 72.9416\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 57.5560\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 47.6097\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 40.0667\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 34.8208\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 31.2431\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 29.2856\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 27.8917\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 291us/step - loss: 26.7141\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 25.8277\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 289us/step - loss: 25.0007\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 289us/step - loss: 24.4439\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 23.5761\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 23.4216\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 284us/step - loss: 22.7647\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 286us/step - loss: 22.1967\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 21.7089\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 21.4277\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 20.9321\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 20.7232\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 20.2990\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 289us/step - loss: 20.0347\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 19.6530\n",
      "Epoch 32/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 285us/step - loss: 19.3511\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 295us/step - loss: 19.0447\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 290us/step - loss: 18.6879\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 18.4654\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 18.0226\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 17.8036\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 17.4416\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 313us/step - loss: 17.2190\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 386us/step - loss: 16.9479\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 373us/step - loss: 16.7174\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 16.4622\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 16.1721\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 15.9551\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 15.6928\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 15.4662\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 297us/step - loss: 15.2004\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 15.0126\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 278us/step - loss: 14.7026\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 14.6340\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 293us/step - loss: 14.3464\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 325us/step - loss: 14.1153\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 13.9435\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 13.8106\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 13.5723\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 13.5773\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 295us/step - loss: 13.2778\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 13.2138\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 13.1397\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 278us/step - loss: 12.8036\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 12.8065\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 12.6847\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 295us/step - loss: 12.5975\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 295us/step - loss: 12.5670\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 12.2898\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 12.2396\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 12.2163\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 287us/step - loss: 12.1904\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 12.0003\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 283us/step - loss: 11.9647\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 282us/step - loss: 11.8654\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 297us/step - loss: 11.7313\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 11.7404\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 286us/step - loss: 11.6224\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 281us/step - loss: 11.5084\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 370us/step - loss: 11.4039\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 363us/step - loss: 11.3034\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 11.3709\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 11.3206\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 291us/step - loss: 11.2483\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 11.1105\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 288us/step - loss: 11.1246\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 293us/step - loss: 11.0112\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 10.9440\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 11.0010\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 10.9322\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 10.8572\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.8618\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.8968\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.7646\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 10.7715\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 10.6990\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 332us/step - loss: 10.8007\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.6573\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 381us/step - loss: 10.6241\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 456us/step - loss: 10.6566\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 346us/step - loss: 10.6497\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 10.5105\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 10.4890\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 326us/step - loss: 10.5018\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 10.4149\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 313us/step - loss: 10.5207\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 347us/step - loss: 10.4081\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 10.3671\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 10.4304\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 10.3094\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 332us/step - loss: 10.4091\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 10.3265\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 355us/step - loss: 10.3080\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 406us/step - loss: 10.2531\n",
      "51/51 [==============================] - 2s 44ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 11ms/step - loss: 534.5902\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 507.5508\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 443.1598\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 343.7780\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 228.8282\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 129.9988\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 79.7648\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 59.2693\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 47.5964\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 310us/step - loss: 39.3291\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 34.4175\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 31.3363\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 29.6825\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 28.2519\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 27.0597\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 25.9717\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 403us/step - loss: 25.0614\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 370us/step - loss: 24.2044\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 23.4337\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 22.6732\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 21.9383\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 21.4494\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 20.8587\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 20.3663\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 19.8771\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 19.4151\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 18.9982\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 306us/step - loss: 18.4912\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 297us/step - loss: 17.9951\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 17.7330\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 17.3372\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 17.0279\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 16.6214\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 16.3465\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 16.0480\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 15.7527\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 15.4857\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 15.1452\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 383us/step - loss: 14.9067\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 429us/step - loss: 14.6386\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 375us/step - loss: 14.5246\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 14.3954\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 14.1833\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 13.9489\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 13.7466\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 13.7144\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 13.4363\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 308us/step - loss: 13.3089\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 297us/step - loss: 13.2302\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 298us/step - loss: 13.0265\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 379us/step - loss: 12.9513\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 390us/step - loss: 12.7299\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 12.7315\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 12.4483\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 12.4480\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 12.3919\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 301us/step - loss: 12.0793\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 304us/step - loss: 12.1524\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 12.0459\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 12.0118\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.8312\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.7273\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 11.6788\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 11.6286\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 11.5824\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 11.5070\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.3603\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 11.3879\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 326us/step - loss: 11.2711\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 11.2702\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 11.1942\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 11.1193\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 11.0872\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 10.9851\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 339us/step - loss: 10.9035\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.7889\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 10.8602\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.7413\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 337us/step - loss: 10.7018\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 10.6765\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 10.6722\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 10.5255\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.4824\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 346us/step - loss: 10.5401\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 426us/step - loss: 10.3821\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 384us/step - loss: 10.4702\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 341us/step - loss: 10.3559\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 332us/step - loss: 10.1880\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 10.3324\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.2496\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 10.1471\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 10.1284\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 313us/step - loss: 10.1685\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 10.1069\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 334us/step - loss: 10.1693\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 10.0557\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.1094\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 321us/step - loss: 10.0357\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 9.9641\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 9.8990\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 9.9248\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 9.9272\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 9.9501\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 334us/step - loss: 9.8171\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 9.8947\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 321us/step - loss: 9.8080\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 9.8026\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 9.7662\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 9.7788\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 9.7577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 2s 44ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 6s 12ms/step - loss: 596.8739\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 567.8636\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 504.4702\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 402.8458\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 281.6387\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 321us/step - loss: 167.9426\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 336us/step - loss: 98.3881\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 331us/step - loss: 69.3095\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 55.5402\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 45.7042\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 39.1954\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 35.2442\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 320us/step - loss: 32.6849\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 30.9860\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 29.7492\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 340us/step - loss: 28.6118\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 27.5792\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 26.7065\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 25.9549\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 357us/step - loss: 25.1809\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 427us/step - loss: 24.5976\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 396us/step - loss: 23.9911\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 341us/step - loss: 23.3217\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 338us/step - loss: 22.8744\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 327us/step - loss: 22.4100\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 320us/step - loss: 21.7588\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 21.2899\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 20.8249\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 20.2641\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 19.8387\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 19.4196\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 18.9459\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 18.5472\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 18.1221\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 336us/step - loss: 17.7589\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 320us/step - loss: 17.3532\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 16.8558\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 305us/step - loss: 16.7355\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 16.4067\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 15.9945\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 341us/step - loss: 15.7208\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 15.4983\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 15.2176\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 327us/step - loss: 14.9686\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 351us/step - loss: 14.7091\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 320us/step - loss: 14.4296\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 14.2604\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 13.9954\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 0s 321us/step - loss: 13.7838\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 13.7101\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 13.4569\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 372us/step - loss: 13.2084\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 398us/step - loss: 13.1271\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 420us/step - loss: 13.0467\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 433us/step - loss: 12.8135\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 343us/step - loss: 12.7069\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 344us/step - loss: 12.7091\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 12.5485\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 308us/step - loss: 12.4360\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 352us/step - loss: 12.38280s - loss: 13.48\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 12.3290\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 12.2104\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 293us/step - loss: 12.1404\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 12.0221\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 11.8931\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 11.9249\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 11.6488\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 11.7878\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 339us/step - loss: 11.6725\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 11.6503\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 323us/step - loss: 11.5903\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 11.4908\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 11.4103\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 11.4309\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - ETA: 0s - loss: 11.05 - 0s 327us/step - loss: 11.2764\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 323us/step - loss: 11.2555\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 11.2240\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 11.1645\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 11.1853\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 398us/step - loss: 11.0290\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 411us/step - loss: 10.9372\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 359us/step - loss: 11.0508\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 0s 417us/step - loss: 10.8289\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 10.9830\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 426us/step - loss: 10.8274\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 429us/step - loss: 10.8467\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 372us/step - loss: 10.7124\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 420us/step - loss: 10.6989\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 334us/step - loss: 10.6208\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 10.5443\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 10.6472\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 395us/step - loss: 10.6161\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 313us/step - loss: 10.5577\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 320us/step - loss: 10.5493\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 303us/step - loss: 10.4306\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 413us/step - loss: 10.4162\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 10.4265\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 311us/step - loss: 10.3332\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 314us/step - loss: 10.3198\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 10.2685\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 409us/step - loss: 10.2862\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 10.2218\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 10.1954\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 312us/step - loss: 10.1880\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 10.1019\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 407us/step - loss: 10.1833\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 381us/step - loss: 10.1614\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 375us/step - loss: 10.0423\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 379us/step - loss: 10.0822\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 372us/step - loss: 10.0069\n",
      "50/50 [==============================] - 2s 44ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 5s 11ms/step - loss: 602.8012\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 584.7205\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 549.1316\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 490.9775\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 410.2168\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 314.8110\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 217.6192\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 134.8853\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 86.4027\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 60.1401\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 46.6123\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 320us/step - loss: 37.0209\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 30.5545\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 26.7347\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 24.3360\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 22.9376\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 21.9687\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 21.1264\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 20.5748\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 340us/step - loss: 19.7455\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 19.2913\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 318us/step - loss: 18.6611\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 344us/step - loss: 18.2256\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 413us/step - loss: 17.8598\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 391us/step - loss: 17.3862\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 339us/step - loss: 16.9255\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 306us/step - loss: 16.5191\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 16.1402\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 293us/step - loss: 15.8522\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 15.4422\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 309us/step - loss: 15.1329\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 14.7971\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 316us/step - loss: 14.5139\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 14.0195\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 13.8956\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 13.5920\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 13.2805\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 13.0404\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 339us/step - loss: 12.7159\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 12.4968\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 12.2738\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 307us/step - loss: 11.9280\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 339us/step - loss: 11.6217\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 11.4082\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 11.1360\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 10.9066\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 350us/step - loss: 10.6637\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 10.4301\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 0s 311us/step - loss: 10.1820\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 9.9909\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 344us/step - loss: 9.7041\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 9.5488\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 356us/step - loss: 9.3372\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 346us/step - loss: 9.0908\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 8.9175\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 365us/step - loss: 8.7515\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 418us/step - loss: 8.5665\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 385us/step - loss: 8.4587\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 352us/step - loss: 8.2884\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 343us/step - loss: 8.1717\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 8.0713\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 7.9934\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 7.8580\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 7.7773\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 325us/step - loss: 7.6925\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 359us/step - loss: 7.5960\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 341us/step - loss: 7.5450\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 7.4162\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 303us/step - loss: 7.4142\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 334us/step - loss: 7.3520\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 311us/step - loss: 7.2595\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - ETA: 0s - loss: 7.156 - 0s 339us/step - loss: 7.2106\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 433us/step - loss: 7.1405\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 346us/step - loss: 7.1407\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 0s 339us/step - loss: 7.0222\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 342us/step - loss: 6.9564\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 6.9774\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 356us/step - loss: 6.9101\n",
      "Epoch 79/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 0s 339us/step - loss: 6.8374\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 350us/step - loss: 6.8073\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 6.7916\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 6.7851\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 6.6654\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 6.6519\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 334us/step - loss: 6.6440\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 348us/step - loss: 6.5718\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 6.6168\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 379us/step - loss: 6.5132\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 410us/step - loss: 6.4776\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 380us/step - loss: 6.5067\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 6.4620\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 6.4150\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 343us/step - loss: 6.4043\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 321us/step - loss: 6.4258\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 6.3508\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 6.3372\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 325us/step - loss: 6.3227\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 341us/step - loss: 6.2432\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 6.2639\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 6.2492\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 6.2165\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 323us/step - loss: 6.1853\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 316us/step - loss: 6.0801\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 6.1593\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 6.1341\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 6.0685\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 6.1090\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 6.0707\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 6.0519\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 352us/step - loss: 6.0216\n",
      "50/50 [==============================] - 2s 46ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 5s 12ms/step - loss: 628.9317\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 306us/step - loss: 602.9117\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 545.5137\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 308us/step - loss: 452.8565\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 331.6094\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 211.8859\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 313us/step - loss: 125.2430\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 81.9467\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 61.0888\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 47.9171\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 308us/step - loss: 39.7260\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 311us/step - loss: 35.9908\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 33.8376\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 340us/step - loss: 32.3366\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 30.9241\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 306us/step - loss: 29.6189\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 306us/step - loss: 28.7139\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 27.6134\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 308us/step - loss: 26.4806\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 25.6345\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 24.8527\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 307us/step - loss: 24.0982\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 298us/step - loss: 23.3278\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 22.6602\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 21.9753\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 21.2506\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 383us/step - loss: 20.6318\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 396us/step - loss: 20.1197\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 350us/step - loss: 19.6585\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 318us/step - loss: 18.9913\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 18.6494\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 313us/step - loss: 18.1643\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 17.6035\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 17.3589\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 16.9160\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 16.3799\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 331us/step - loss: 16.0742\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 343us/step - loss: 15.7544\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 15.5392\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 15.1993\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 14.8083\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 14.5728\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 14.1501\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 340us/step - loss: 14.1212\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 350us/step - loss: 13.8250\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 321us/step - loss: 13.5408\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 344us/step - loss: 13.3948\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 334us/step - loss: 13.1517\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 12.9296\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 405us/step - loss: 12.7319\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 343us/step - loss: 12.6247\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 12.4038\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 343us/step - loss: 12.2445\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 12.0865\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 11.9256\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 11.7037\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 11.6542\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 11.4885\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 334us/step - loss: 11.2636\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 396us/step - loss: 11.0818\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 391us/step - loss: 11.1541\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 11.0696\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 10.7939\n",
      "Epoch 64/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 0s 333us/step - loss: 10.7235\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 10.6292\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 10.4044\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 10.4879\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 10.3207\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 10.3148\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 10.1562\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 10.1332\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 10.0547\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 9.9504\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 9.8814\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 0s 329us/step - loss: 9.8726\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 327us/step - loss: 9.8329\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 9.6975\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 9.6435\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 9.6721\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 9.5458\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 9.4778\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 348us/step - loss: 9.4181\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 9.2679\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 338us/step - loss: 9.3492\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 327us/step - loss: 9.3147\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 340us/step - loss: 9.2828\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 308us/step - loss: 9.2512\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 309us/step - loss: 9.1302\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 9.0886\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 9.1845\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 9.0013\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 297us/step - loss: 8.9303\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 378us/step - loss: 8.9681\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 359us/step - loss: 8.9402\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 357us/step - loss: 8.8676\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 8.7897\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 8.7201\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 8.7537\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 293us/step - loss: 8.7186\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 8.7561\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 8.6028\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 289us/step - loss: 8.6931\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 8.6130\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 8.5652\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 342us/step - loss: 8.4528\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 8.5140\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 8.5666\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 8.4587\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 8.4812\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 8.4028\n",
      "50/50 [==============================] - 2s 44ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 5s 12ms/step - loss: 612.6245\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 363us/step - loss: 595.3087\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 554.4265\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 486.1567\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 323us/step - loss: 390.5988\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 327us/step - loss: 275.8162\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 173.5864\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 108.3219\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 350us/step - loss: 80.6116\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 63.7195\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 50.7660\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 311us/step - loss: 41.4763\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 35.1214\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 293us/step - loss: 32.3191\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 299us/step - loss: 30.4124\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 29.0330\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 296us/step - loss: 28.2214\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 27.2917\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 26.6641\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 307us/step - loss: 25.9468\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 289us/step - loss: 25.2603\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 24.6857\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 24.0306\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 23.6497\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 23.0649\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 22.6318\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 303us/step - loss: 22.1965\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 308us/step - loss: 21.7314\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 21.3284\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 20.9380\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 383us/step - loss: 20.6605\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 438us/step - loss: 20.2637\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 417us/step - loss: 19.8910\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 461us/step - loss: 19.6360\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 19.2312\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 422us/step - loss: 18.8868\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 313us/step - loss: 18.5051\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 18.3860\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 407us/step - loss: 17.8945\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 318us/step - loss: 17.5814\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 17.2946\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 16.9958\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 409us/step - loss: 16.6859\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 311us/step - loss: 16.4229\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 320us/step - loss: 16.1513\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 15.7294\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 412us/step - loss: 15.6096\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 322us/step - loss: 15.2760\n",
      "Epoch 49/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 0s 304us/step - loss: 15.0114\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 14.8900\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 306us/step - loss: 14.7332\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 409us/step - loss: 14.5275\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 305us/step - loss: 14.3360\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 305us/step - loss: 14.1198\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 13.9826\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 294us/step - loss: 13.8279\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 356us/step - loss: 13.5933\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 375us/step - loss: 13.5299\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 13.2035\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 13.3181\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 13.1173\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 297us/step - loss: 12.9236\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 299us/step - loss: 12.8656\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 0s 299us/step - loss: 12.6726\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 387us/step - loss: 12.5415\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 385us/step - loss: 12.5339\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 12.3796\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 0s 302us/step - loss: 12.2413\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 304us/step - loss: 12.1766\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 289us/step - loss: 12.1092\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 291us/step - loss: 11.9960\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 0s 297us/step - loss: 11.7783\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 11.8434\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 289us/step - loss: 11.6669\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 0s 298us/step - loss: 11.4867\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 295us/step - loss: 11.3954\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 11.3725\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 327us/step - loss: 11.2701\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 0s 319us/step - loss: 11.1700\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 11.1695\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 331us/step - loss: 11.0180\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 10.9414\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 10.8798\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 345us/step - loss: 10.7286\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 10.7207\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 339us/step - loss: 10.6682\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 317us/step - loss: 10.6031\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 336us/step - loss: 10.5793\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 338us/step - loss: 10.4166\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 10.4721\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 335us/step - loss: 10.4148\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 337us/step - loss: 10.3123\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 324us/step - loss: 10.2930\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 313us/step - loss: 10.2870\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 330us/step - loss: 10.1965\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 10.1510\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 323us/step - loss: 10.0437\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 363us/step - loss: 10.0293\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 403us/step - loss: 9.9432\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 396us/step - loss: 9.9316\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 308us/step - loss: 9.9097\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 9.7958\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 307us/step - loss: 9.8455\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 303us/step - loss: 9.7557\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 300us/step - loss: 9.7084\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 326us/step - loss: 9.6338\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 333us/step - loss: 9.6522\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 328us/step - loss: 9.6160\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 332us/step - loss: 9.5084\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 315us/step - loss: 9.3703\n",
      "50/50 [==============================] - 2s 45ms/step\n",
      "Larger: -20.85 (24.96) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs, and second layer of 7 neurons, changing batch size to 10\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(7, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=10, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "455/455 [==============================] - 7s 14ms/step - loss: 597.3289\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 932us/step - loss: 547.3509\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 962us/step - loss: 440.1749\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 662us/step - loss: 290.0866\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 678us/step - loss: 151.7858\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 813us/step - loss: 75.9759\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 809us/step - loss: 52.8096\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 923us/step - loss: 40.4388\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 854us/step - loss: 33.5877\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 29.8169\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 27.7314\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 25.9901\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 24.9937\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 788us/step - loss: 23.9472\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 704us/step - loss: 23.0078\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 796us/step - loss: 22.4231\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 630us/step - loss: 21.6976\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 703us/step - loss: 21.4320\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 676us/step - loss: 20.8199\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 20.4027\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 688us/step - loss: 19.6980\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 792us/step - loss: 19.4222\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 783us/step - loss: 18.9723\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 657us/step - loss: 18.5748\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 618us/step - loss: 18.0008\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 673us/step - loss: 17.7314\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 604us/step - loss: 17.3938\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 595us/step - loss: 16.7946\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 671us/step - loss: 16.6696\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 993us/step - loss: 16.3301\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 985us/step - loss: 16.0142\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 728us/step - loss: 15.5589\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 668us/step - loss: 15.1097\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 704us/step - loss: 15.1361\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 651us/step - loss: 14.7872\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 575us/step - loss: 14.4568\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 624us/step - loss: 14.1986\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 574us/step - loss: 14.0293\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 522us/step - loss: 13.7738\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 574us/step - loss: 13.5796\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 598us/step - loss: 13.2940\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 572us/step - loss: 13.1106\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 593us/step - loss: 12.8618\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 836us/step - loss: 12.7528\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 445us/step - loss: 12.5927\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 12.3356\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 12.2393\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 12.1127\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 11.7583\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 718us/step - loss: 11.9078\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 481us/step - loss: 11.7170\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 11.5803\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 11.5387\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 399us/step - loss: 11.4271\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 11.2156\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 11.1793\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 11.1174\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 11.1098\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 10.9573\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 389us/step - loss: 11.0208\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.7582\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 10.8853\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 481us/step - loss: 10.8525\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 515us/step - loss: 10.7154\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 530us/step - loss: 10.6684\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 481us/step - loss: 10.4790\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 618us/step - loss: 10.5104\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 10.4899\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 465us/step - loss: 10.55340s - loss: 7.3\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.4354\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.4817\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.4073\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 652us/step - loss: 10.3385\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 478us/step - loss: 10.4009\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.2930\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.2867\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 481us/step - loss: 10.1299\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 10.1588\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 366us/step - loss: 9.9056\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.0988\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 10.0394\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 10.0501\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 9.8628\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 438us/step - loss: 9.8289\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 9.8451\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 9.8705\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 9.8999\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 9.6886\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 9.7564\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 401us/step - loss: 9.6472\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 9.7632\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 840us/step - loss: 9.8352\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 642us/step - loss: 9.6583\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 545us/step - loss: 9.6647\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 668us/step - loss: 9.6345\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 624us/step - loss: 9.7268\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 569us/step - loss: 9.5724\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 9.6176\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 923us/step - loss: 9.6087\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 800us/step - loss: 9.5919\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 9.4584\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 508us/step - loss: 9.4843\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 687us/step - loss: 9.3557\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 501us/step - loss: 9.4633\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 554us/step - loss: 9.4957\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 765us/step - loss: 9.4049\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 607us/step - loss: 9.4865\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 9.3518\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 1ms/step - loss: 9.3815\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 730us/step - loss: 9.4227\n",
      "51/51 [==============================] - 3s 64ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 11ms/step - loss: 580.9856\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 538.9003\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 371us/step - loss: 446.1040\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 314.5687\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 366us/step - loss: 174.3516\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 93.8421\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 435us/step - loss: 62.5991\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 510us/step - loss: 47.5505\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 39.0660\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 402us/step - loss: 34.3451\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 408us/step - loss: 31.7651\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 29.9410\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 354us/step - loss: 28.6641\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 362us/step - loss: 27.6920\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 26.6591\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 346us/step - loss: 25.8477\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 515us/step - loss: 25.1035\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 655us/step - loss: 24.4059\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 362us/step - loss: 23.7182\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 330us/step - loss: 23.0552\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 335us/step - loss: 22.4082\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 380us/step - loss: 21.8462\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 21.1617\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 20.7335\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 20.2316\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 19.6297\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 19.1796\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 348us/step - loss: 18.6288\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 18.3535\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 17.9733\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 17.6171\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 347us/step - loss: 17.1999\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 365us/step - loss: 16.8693\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 337us/step - loss: 16.5833\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 354us/step - loss: 16.2907\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 15.8233\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 15.6159\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 353us/step - loss: 15.3190\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 15.1092\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 365us/step - loss: 14.9073\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 14.6771\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 14.4530\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 14.2250\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 14.0619\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 13.8869\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 331us/step - loss: 13.6175\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 361us/step - loss: 13.4833\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 13.3103\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 13.2118\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 13.0967\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 12.9072\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 353us/step - loss: 12.8135\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 12.7870\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 12.5704\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 12.4569\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 12.2604\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 12.3161\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 12.1183\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 340us/step - loss: 12.0898\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 304us/step - loss: 12.0028\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 11.9137\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 11.6998\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 11.7603\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.6126\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 11.5134\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 342us/step - loss: 11.4612\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 304us/step - loss: 11.3959\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 11.3796\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 11.2794\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.2404\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 11.1174\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 354us/step - loss: 11.0599\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 303us/step - loss: 11.0313\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 11.0147\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.9519\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.9035\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.9018\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.8567\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 339us/step - loss: 10.7903\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 370us/step - loss: 10.6290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.6099\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.6471\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.5409\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.5671\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 363us/step - loss: 10.5814\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 424us/step - loss: 10.4956\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 431us/step - loss: 10.3429\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 333us/step - loss: 10.4242\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 336us/step - loss: 10.4145\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.4678\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.3169\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 321us/step - loss: 10.3691\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 363us/step - loss: 10.4274\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 10.2705\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 330us/step - loss: 10.1887\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.1969\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.1727\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 10.1592\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 346us/step - loss: 10.1816\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.1089\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 354us/step - loss: 10.0775\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.0615\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.0250\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.0373\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 10.0093\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 330us/step - loss: 9.8958\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 9.9470\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 9.8779\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 9.8802\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 9.9459\n",
      "51/51 [==============================] - 2s 40ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 11ms/step - loss: 612.9957\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 304us/step - loss: 565.2568\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 453.8703\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 291.2079\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 610us/step - loss: 148.9371\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 305us/step - loss: 82.2585\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 339us/step - loss: 58.5038\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 45.5572\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 38.5307\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 381us/step - loss: 35.2266\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 33.3201\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 347us/step - loss: 31.5032\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 30.5496\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 337us/step - loss: 29.2476\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 27.9977\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 27.0228\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 26.0679\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 25.1471\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 24.3395\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 23.6302\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 22.8114\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 22.2435\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 21.5660\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 21.0129\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 20.2409\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 19.5877\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 19.2353\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 18.6391\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 18.2783\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 482us/step - loss: 17.7796\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 572us/step - loss: 17.3718\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 420us/step - loss: 17.0355\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 392us/step - loss: 16.6750\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 412us/step - loss: 16.2629\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 16.0371\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 363us/step - loss: 15.7559\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 417us/step - loss: 15.5414\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 15.3124\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 15.1234\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 14.8273\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 14.6302\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 14.4826\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 14.1423\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 14.1712\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 354us/step - loss: 14.1794\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 535us/step - loss: 13.7043\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 306us/step - loss: 13.6624\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 13.4974\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 523us/step - loss: 13.3829\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 13.3310\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 314us/step - loss: 13.1841\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 525us/step - loss: 13.1342\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 392us/step - loss: 12.8312\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 12.7296\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 311us/step - loss: 12.7467\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 471us/step - loss: 12.5308\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 12.3606\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 12.4541\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 12.1085\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 12.1316\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 11.9578\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 11.9863\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.9508\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 11.8051\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.7436\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.6970\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 304us/step - loss: 11.5262\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 324us/step - loss: 11.5565\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 11.5890\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 11.4006\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.4898\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.3778\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.3132\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 11.2726\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 11.2582\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 441us/step - loss: 11.1350\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 11.0629\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 11.0487\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 337us/step - loss: 11.0082\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 302us/step - loss: 11.0414\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 345us/step - loss: 10.9494\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 328us/step - loss: 10.8439\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 11.0139\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.8951\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.7885\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.8296\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 327us/step - loss: 10.7269\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 306us/step - loss: 10.7721\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.6901\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 347us/step - loss: 10.6640\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.7158\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.6447\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.6433\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.5860\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 322us/step - loss: 10.4921\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 336us/step - loss: 10.4661\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 294us/step - loss: 10.6041\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.4974\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.5245\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.4162\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 320us/step - loss: 10.3621\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 10.4222\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 355us/step - loss: 10.3832\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.3344\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.1812\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.3009\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 10.2162\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 338us/step - loss: 10.2137\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 343us/step - loss: 10.2337\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 321us/step - loss: 10.1828\n",
      "51/51 [==============================] - 2s 38ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 10ms/step - loss: 530.0245\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 312us/step - loss: 484.6839\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 380.8616\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 275us/step - loss: 236.5406\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 118.6571\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 70.6497\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 53.8379\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 44.1093\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 309us/step - loss: 38.7387\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 344us/step - loss: 35.5588\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 369us/step - loss: 33.6104\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 360us/step - loss: 31.9061\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 317us/step - loss: 30.3827\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 29.0550\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 326us/step - loss: 27.6890\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 334us/step - loss: 26.5754\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 316us/step - loss: 25.6904\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 318us/step - loss: 24.5970\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 23.5316\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 319us/step - loss: 22.7286\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 346us/step - loss: 22.0194\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 571us/step - loss: 21.2605\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 527us/step - loss: 20.4787\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 545us/step - loss: 19.9554\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 527us/step - loss: 19.5233\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 457us/step - loss: 18.8709\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 439us/step - loss: 18.2371\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 448us/step - loss: 17.8258\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 422us/step - loss: 17.5285\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 16.9873\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 16.5259\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 16.1120\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 15.6304\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 510us/step - loss: 15.2759\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 545us/step - loss: 15.0494\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 528us/step - loss: 14.6776\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 466us/step - loss: 14.3754\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 369us/step - loss: 14.0656\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 378us/step - loss: 13.8289\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 396us/step - loss: 13.7567\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 466us/step - loss: 13.4986\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 580us/step - loss: 13.2391\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 510us/step - loss: 13.0830\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 545us/step - loss: 12.9214\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 677us/step - loss: 12.7630\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 554us/step - loss: 12.6107\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 730us/step - loss: 12.4165\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 879us/step - loss: 12.3850\n",
      "Epoch 49/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 765us/step - loss: 12.1339\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 738us/step - loss: 12.0977\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 739us/step - loss: 11.9972\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 653us/step - loss: 11.8765\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 703us/step - loss: 11.6918\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 624us/step - loss: 11.5367\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 625us/step - loss: 11.5480\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 501us/step - loss: 11.4138\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 474us/step - loss: 11.3663\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 499us/step - loss: 11.2216\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 477us/step - loss: 11.0739\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 537us/step - loss: 11.1123\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 696us/step - loss: 11.0042\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 554us/step - loss: 10.8353\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 651us/step - loss: 10.8208\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 518us/step - loss: 10.7481\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 483us/step - loss: 10.7030\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 528us/step - loss: 10.4072\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 545us/step - loss: 10.4706\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 473us/step - loss: 10.4899\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 428us/step - loss: 10.4015\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 551us/step - loss: 10.3131\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 532us/step - loss: 10.2668\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 532us/step - loss: 10.2281\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 571us/step - loss: 10.1486\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 487us/step - loss: 10.1557\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 528us/step - loss: 10.1000\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 620us/step - loss: 10.0708\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 576us/step - loss: 10.0157\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 568us/step - loss: 9.9613\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 572us/step - loss: 9.8739\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 549us/step - loss: 9.9102\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 644us/step - loss: 9.8859\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 786us/step - loss: 9.7037\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 761us/step - loss: 9.7849\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 639us/step - loss: 9.7246\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 562us/step - loss: 9.7387\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 720us/step - loss: 9.6127\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 630us/step - loss: 9.5923\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 698us/step - loss: 9.4959\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 642us/step - loss: 9.4316\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 686us/step - loss: 9.4753\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 721us/step - loss: 9.4651\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 690us/step - loss: 9.4458\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 629us/step - loss: 9.3166\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 647us/step - loss: 9.3510\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 681us/step - loss: 9.3139\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 656us/step - loss: 9.1471\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 675us/step - loss: 9.2036\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 727us/step - loss: 9.2881\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 770us/step - loss: 9.0885\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 541us/step - loss: 9.1646\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 471us/step - loss: 9.0753\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 524us/step - loss: 9.1014\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 560us/step - loss: 9.0354\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 496us/step - loss: 9.0709\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 420us/step - loss: 9.0382\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 475us/step - loss: 9.0628\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 488us/step - loss: 8.9535\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 435us/step - loss: 8.9178\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 381us/step - loss: 8.7143\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 8.9026\n",
      "51/51 [==============================] - 2s 49ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 6s 12ms/step - loss: 559.7096\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 705us/step - loss: 530.6505\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 729us/step - loss: 454.8658\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 689us/step - loss: 336.7923\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 746us/step - loss: 206.1832\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 754us/step - loss: 107.7185\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 753us/step - loss: 66.0967\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 758us/step - loss: 50.7995\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 759us/step - loss: 40.8194\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 766us/step - loss: 34.6290\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 775us/step - loss: 31.0078\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 804us/step - loss: 28.8550\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 596us/step - loss: 27.3580\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 734us/step - loss: 26.0656\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 705us/step - loss: 25.2667\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 680us/step - loss: 24.4829\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 690us/step - loss: 23.7144\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 698us/step - loss: 23.1165\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 696us/step - loss: 22.4417\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 677us/step - loss: 22.0269\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 657us/step - loss: 21.2040\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 674us/step - loss: 21.1212\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 690us/step - loss: 20.5420\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 656us/step - loss: 19.9746\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 396us/step - loss: 19.4448\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 329us/step - loss: 19.1153\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 314us/step - loss: 18.5718\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 308us/step - loss: 18.2807\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 286us/step - loss: 17.7493\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 315us/step - loss: 17.5028\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 300us/step - loss: 16.8127\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 16.6530\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 284us/step - loss: 16.2886\n",
      "Epoch 34/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 308us/step - loss: 15.9020\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 15.5943\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 292us/step - loss: 15.2460\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 301us/step - loss: 14.9184\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 286us/step - loss: 14.5464\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 14.4192\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 310us/step - loss: 14.1362\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 13.9263\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 286us/step - loss: 13.7876\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 350us/step - loss: 13.5138\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 13.4054\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 13.1928\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 296us/step - loss: 13.0965\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 308us/step - loss: 12.8456\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 286us/step - loss: 12.7661\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 308us/step - loss: 12.4966\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 285us/step - loss: 12.5415\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 307us/step - loss: 12.3104\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 299us/step - loss: 12.2145\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 293us/step - loss: 12.1109\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 304us/step - loss: 12.0651\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 283us/step - loss: 11.8288\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 323us/step - loss: 11.9012\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 399us/step - loss: 11.6882\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 456us/step - loss: 11.6620\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 483us/step - loss: 11.6922\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 660us/step - loss: 11.4966\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 617us/step - loss: 11.4571\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 702us/step - loss: 11.3826\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 623us/step - loss: 11.2946\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 694us/step - loss: 11.3463\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 584us/step - loss: 11.1329\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 675us/step - loss: 11.0919\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 585us/step - loss: 11.0718\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 571us/step - loss: 11.1274\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 747us/step - loss: 10.9660\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 624us/step - loss: 10.9324\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 615us/step - loss: 10.9065\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 738us/step - loss: 10.7753\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 695us/step - loss: 10.8334\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 756us/step - loss: 10.8217\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 826us/step - loss: 10.7354\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 677us/step - loss: 10.6734\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 774us/step - loss: 10.6430\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 779us/step - loss: 10.6444\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 551us/step - loss: 10.6176\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 615us/step - loss: 10.5790\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 501us/step - loss: 10.5588\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 474us/step - loss: 10.5058\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 484us/step - loss: 10.3807\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 463us/step - loss: 10.3802\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 386us/step - loss: 10.4810\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 373us/step - loss: 10.3716\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 345us/step - loss: 10.3735\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 538us/step - loss: 10.4016\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 671us/step - loss: 10.3859\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 621us/step - loss: 10.3391\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 595us/step - loss: 10.3023\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 712us/step - loss: 10.2457\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 703us/step - loss: 10.2901\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 689us/step - loss: 10.2002\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 680us/step - loss: 10.2491\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 737us/step - loss: 10.2082\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 617us/step - loss: 10.2379\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 667us/step - loss: 10.0205\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 708us/step - loss: 10.0868\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 661us/step - loss: 10.0730\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 638us/step - loss: 9.9924\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 670us/step - loss: 10.0806\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 607us/step - loss: 9.9600\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 537us/step - loss: 9.9564\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 693us/step - loss: 10.0343\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 686us/step - loss: 9.8289\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 715us/step - loss: 9.9372\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 744us/step - loss: 9.9155\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 717us/step - loss: 9.9143\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 644us/step - loss: 9.7425\n",
      "51/51 [==============================] - 2s 47ms/step\n",
      "Epoch 1/110\n",
      "455/455 [==============================] - 5s 10ms/step - loss: 531.0825\n",
      "Epoch 2/110\n",
      "455/455 [==============================] - 0s 393us/step - loss: 477.3196\n",
      "Epoch 3/110\n",
      "455/455 [==============================] - 0s 457us/step - loss: 354.5807\n",
      "Epoch 4/110\n",
      "455/455 [==============================] - 0s 416us/step - loss: 199.3217\n",
      "Epoch 5/110\n",
      "455/455 [==============================] - 0s 424us/step - loss: 96.2642\n",
      "Epoch 6/110\n",
      "455/455 [==============================] - 0s 418us/step - loss: 60.9183\n",
      "Epoch 7/110\n",
      "455/455 [==============================] - 0s 659us/step - loss: 45.3035\n",
      "Epoch 8/110\n",
      "455/455 [==============================] - 0s 624us/step - loss: 36.8084\n",
      "Epoch 9/110\n",
      "455/455 [==============================] - 0s 589us/step - loss: 32.6357\n",
      "Epoch 10/110\n",
      "455/455 [==============================] - 0s 439us/step - loss: 29.9936\n",
      "Epoch 11/110\n",
      "455/455 [==============================] - 0s 392us/step - loss: 28.3773\n",
      "Epoch 12/110\n",
      "455/455 [==============================] - 0s 397us/step - loss: 26.8534\n",
      "Epoch 13/110\n",
      "455/455 [==============================] - 0s 510us/step - loss: 25.6911\n",
      "Epoch 14/110\n",
      "455/455 [==============================] - 0s 615us/step - loss: 24.5336\n",
      "Epoch 15/110\n",
      "455/455 [==============================] - 0s 607us/step - loss: 23.5370\n",
      "Epoch 16/110\n",
      "455/455 [==============================] - 0s 607us/step - loss: 22.6917\n",
      "Epoch 17/110\n",
      "455/455 [==============================] - 0s 607us/step - loss: 21.8813\n",
      "Epoch 18/110\n",
      "455/455 [==============================] - 0s 615us/step - loss: 21.2969\n",
      "Epoch 19/110\n",
      "455/455 [==============================] - 0s 607us/step - loss: 20.6129\n",
      "Epoch 20/110\n",
      "455/455 [==============================] - 0s 624us/step - loss: 19.9339\n",
      "Epoch 21/110\n",
      "455/455 [==============================] - 0s 615us/step - loss: 19.3217\n",
      "Epoch 22/110\n",
      "455/455 [==============================] - 0s 475us/step - loss: 18.7689\n",
      "Epoch 23/110\n",
      "455/455 [==============================] - 0s 462us/step - loss: 18.4242\n",
      "Epoch 24/110\n",
      "455/455 [==============================] - 0s 510us/step - loss: 17.9177\n",
      "Epoch 25/110\n",
      "455/455 [==============================] - 0s 431us/step - loss: 17.4168\n",
      "Epoch 26/110\n",
      "455/455 [==============================] - 0s 437us/step - loss: 17.0252\n",
      "Epoch 27/110\n",
      "455/455 [==============================] - 0s 454us/step - loss: 16.6641\n",
      "Epoch 28/110\n",
      "455/455 [==============================] - 0s 530us/step - loss: 16.2181\n",
      "Epoch 29/110\n",
      "455/455 [==============================] - 0s 527us/step - loss: 15.7674\n",
      "Epoch 30/110\n",
      "455/455 [==============================] - 0s 653us/step - loss: 15.5811\n",
      "Epoch 31/110\n",
      "455/455 [==============================] - 0s 598us/step - loss: 15.2971\n",
      "Epoch 32/110\n",
      "455/455 [==============================] - 0s 510us/step - loss: 14.9814\n",
      "Epoch 33/110\n",
      "455/455 [==============================] - 0s 406us/step - loss: 14.7224\n",
      "Epoch 34/110\n",
      "455/455 [==============================] - 0s 351us/step - loss: 14.4996\n",
      "Epoch 35/110\n",
      "455/455 [==============================] - 0s 414us/step - loss: 14.1913\n",
      "Epoch 36/110\n",
      "455/455 [==============================] - 0s 422us/step - loss: 13.9709\n",
      "Epoch 37/110\n",
      "455/455 [==============================] - 0s 435us/step - loss: 13.8214\n",
      "Epoch 38/110\n",
      "455/455 [==============================] - 0s 410us/step - loss: 13.5725\n",
      "Epoch 39/110\n",
      "455/455 [==============================] - 0s 432us/step - loss: 13.5045\n",
      "Epoch 40/110\n",
      "455/455 [==============================] - 0s 372us/step - loss: 13.2440\n",
      "Epoch 41/110\n",
      "455/455 [==============================] - 0s 453us/step - loss: 13.2330\n",
      "Epoch 42/110\n",
      "455/455 [==============================] - 0s 433us/step - loss: 13.0899\n",
      "Epoch 43/110\n",
      "455/455 [==============================] - 0s 362us/step - loss: 12.9248\n",
      "Epoch 44/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 12.6334\n",
      "Epoch 45/110\n",
      "455/455 [==============================] - 0s 428us/step - loss: 12.6026\n",
      "Epoch 46/110\n",
      "455/455 [==============================] - 0s 439us/step - loss: 12.5133\n",
      "Epoch 47/110\n",
      "455/455 [==============================] - 0s 400us/step - loss: 12.3777\n",
      "Epoch 48/110\n",
      "455/455 [==============================] - 0s 426us/step - loss: 12.2110\n",
      "Epoch 49/110\n",
      "455/455 [==============================] - 0s 415us/step - loss: 12.1891\n",
      "Epoch 50/110\n",
      "455/455 [==============================] - 0s 364us/step - loss: 12.0968\n",
      "Epoch 51/110\n",
      "455/455 [==============================] - 0s 480us/step - loss: 12.0269\n",
      "Epoch 52/110\n",
      "455/455 [==============================] - 0s 422us/step - loss: 11.8025\n",
      "Epoch 53/110\n",
      "455/455 [==============================] - 0s 435us/step - loss: 11.8795\n",
      "Epoch 54/110\n",
      "455/455 [==============================] - 0s 437us/step - loss: 11.5731\n",
      "Epoch 55/110\n",
      "455/455 [==============================] - 0s 404us/step - loss: 11.6432\n",
      "Epoch 56/110\n",
      "455/455 [==============================] - 0s 419us/step - loss: 11.5634\n",
      "Epoch 57/110\n",
      "455/455 [==============================] - 0s 422us/step - loss: 11.3413\n",
      "Epoch 58/110\n",
      "455/455 [==============================] - 0s 444us/step - loss: 11.4001\n",
      "Epoch 59/110\n",
      "455/455 [==============================] - 0s 401us/step - loss: 11.2393\n",
      "Epoch 60/110\n",
      "455/455 [==============================] - 0s 431us/step - loss: 11.2522\n",
      "Epoch 61/110\n",
      "455/455 [==============================] - 0s 402us/step - loss: 11.0980\n",
      "Epoch 62/110\n",
      "455/455 [==============================] - 0s 425us/step - loss: 10.9994\n",
      "Epoch 63/110\n",
      "455/455 [==============================] - 0s 433us/step - loss: 10.9561\n",
      "Epoch 64/110\n",
      "455/455 [==============================] - 0s 442us/step - loss: 10.9456\n",
      "Epoch 65/110\n",
      "455/455 [==============================] - 0s 439us/step - loss: 10.8776\n",
      "Epoch 66/110\n",
      "455/455 [==============================] - 0s 444us/step - loss: 10.8493\n",
      "Epoch 67/110\n",
      "455/455 [==============================] - 0s 420us/step - loss: 10.6348\n",
      "Epoch 68/110\n",
      "455/455 [==============================] - 0s 451us/step - loss: 10.6596\n",
      "Epoch 69/110\n",
      "455/455 [==============================] - 0s 422us/step - loss: 10.5862\n",
      "Epoch 70/110\n",
      "455/455 [==============================] - 0s 436us/step - loss: 10.6457\n",
      "Epoch 71/110\n",
      "455/455 [==============================] - 0s 419us/step - loss: 10.5653\n",
      "Epoch 72/110\n",
      "455/455 [==============================] - 0s 442us/step - loss: 10.5529\n",
      "Epoch 73/110\n",
      "455/455 [==============================] - 0s 439us/step - loss: 10.5553\n",
      "Epoch 74/110\n",
      "455/455 [==============================] - 0s 411us/step - loss: 10.4255\n",
      "Epoch 75/110\n",
      "455/455 [==============================] - 0s 433us/step - loss: 10.4561\n",
      "Epoch 76/110\n",
      "455/455 [==============================] - 0s 442us/step - loss: 10.3235\n",
      "Epoch 77/110\n",
      "455/455 [==============================] - 0s 442us/step - loss: 10.3108\n",
      "Epoch 78/110\n",
      "455/455 [==============================] - 0s 441us/step - loss: 10.2662\n",
      "Epoch 79/110\n",
      "455/455 [==============================] - 0s 438us/step - loss: 10.2179\n",
      "Epoch 80/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 10.2823\n",
      "Epoch 81/110\n",
      "455/455 [==============================] - 0s 427us/step - loss: 10.2875\n",
      "Epoch 82/110\n",
      "455/455 [==============================] - 0s 462us/step - loss: 10.0821\n",
      "Epoch 83/110\n",
      "455/455 [==============================] - 0s 433us/step - loss: 10.1240\n",
      "Epoch 84/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 10.2278\n",
      "Epoch 85/110\n",
      "455/455 [==============================] - 0s 458us/step - loss: 10.0209\n",
      "Epoch 86/110\n",
      "455/455 [==============================] - 0s 400us/step - loss: 10.1265\n",
      "Epoch 87/110\n",
      "455/455 [==============================] - 0s 484us/step - loss: 9.9934\n",
      "Epoch 88/110\n",
      "455/455 [==============================] - 0s 458us/step - loss: 9.8517\n",
      "Epoch 89/110\n",
      "455/455 [==============================] - 0s 425us/step - loss: 10.0266\n",
      "Epoch 90/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 9.8846\n",
      "Epoch 91/110\n",
      "455/455 [==============================] - 0s 415us/step - loss: 9.8885\n",
      "Epoch 92/110\n",
      "455/455 [==============================] - 0s 453us/step - loss: 9.8430\n",
      "Epoch 93/110\n",
      "455/455 [==============================] - 0s 437us/step - loss: 9.9829\n",
      "Epoch 94/110\n",
      "455/455 [==============================] - 0s 460us/step - loss: 9.8484\n",
      "Epoch 95/110\n",
      "455/455 [==============================] - 0s 418us/step - loss: 9.8586\n",
      "Epoch 96/110\n",
      "455/455 [==============================] - 0s 449us/step - loss: 9.8409\n",
      "Epoch 97/110\n",
      "455/455 [==============================] - 0s 460us/step - loss: 9.9117\n",
      "Epoch 98/110\n",
      "455/455 [==============================] - 0s 450us/step - loss: 9.8116\n",
      "Epoch 99/110\n",
      "455/455 [==============================] - 0s 451us/step - loss: 9.7192\n",
      "Epoch 100/110\n",
      "455/455 [==============================] - 0s 427us/step - loss: 9.6307\n",
      "Epoch 101/110\n",
      "455/455 [==============================] - 0s 450us/step - loss: 9.7004\n",
      "Epoch 102/110\n",
      "455/455 [==============================] - 0s 419us/step - loss: 9.7038\n",
      "Epoch 103/110\n",
      "455/455 [==============================] - 0s 427us/step - loss: 9.6817\n",
      "Epoch 104/110\n",
      "455/455 [==============================] - 0s 454us/step - loss: 9.5957\n",
      "Epoch 105/110\n",
      "455/455 [==============================] - 0s 438us/step - loss: 9.6561\n",
      "Epoch 106/110\n",
      "455/455 [==============================] - 0s 450us/step - loss: 9.5991\n",
      "Epoch 107/110\n",
      "455/455 [==============================] - 0s 441us/step - loss: 9.6170\n",
      "Epoch 108/110\n",
      "455/455 [==============================] - 0s 440us/step - loss: 9.5566\n",
      "Epoch 109/110\n",
      "455/455 [==============================] - 0s 424us/step - loss: 9.5933\n",
      "Epoch 110/110\n",
      "455/455 [==============================] - 0s 446us/step - loss: 9.5664\n",
      "51/51 [==============================] - 2s 40ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 5s 11ms/step - loss: 593.3057\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 417us/step - loss: 537.2621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 401us/step - loss: 416.0332\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 373us/step - loss: 245.0634\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 442us/step - loss: 113.3324\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 62.4561\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 424us/step - loss: 46.5795\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 424us/step - loss: 37.7769\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 32.9887\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 446us/step - loss: 30.5008\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 433us/step - loss: 28.6579\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 497us/step - loss: 27.7357\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 436us/step - loss: 26.5012\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 422us/step - loss: 25.6251\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 422us/step - loss: 24.8484\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 435us/step - loss: 23.9889\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 422us/step - loss: 23.2744\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 414us/step - loss: 22.6393\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 428us/step - loss: 22.0739\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 435us/step - loss: 21.4653\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 437us/step - loss: 20.8612\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 434us/step - loss: 20.3279\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 425us/step - loss: 19.7393\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 19.3993\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 406us/step - loss: 18.8852\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 18.2836\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 470us/step - loss: 17.8491\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 402us/step - loss: 17.4315\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 420us/step - loss: 16.8445\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 441us/step - loss: 16.4223\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 429us/step - loss: 16.1112\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 579us/step - loss: 15.6564\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 415us/step - loss: 15.3779\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 410us/step - loss: 15.1709\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 14.8141\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 405us/step - loss: 14.5659\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 14.2381\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 415us/step - loss: 14.0736\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 451us/step - loss: 14.0343\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 433us/step - loss: 13.6847\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 527us/step - loss: 13.5620\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 428us/step - loss: 13.4855\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 435us/step - loss: 13.2817\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 425us/step - loss: 13.1428\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 445us/step - loss: 12.9697\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 12.8415\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 364us/step - loss: 12.7669\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 444us/step - loss: 12.6119\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 0s 414us/step - loss: 12.4811\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 12.5149\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 389us/step - loss: 12.3652\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 400us/step - loss: 12.1163\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 409us/step - loss: 12.1499\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 422us/step - loss: 12.1805\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 416us/step - loss: 11.9365\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 399us/step - loss: 11.8657\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 420us/step - loss: 11.9909\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 380us/step - loss: 11.7828\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 412us/step - loss: 11.7173\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 437us/step - loss: 11.6873\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 407us/step - loss: 11.6456\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 444us/step - loss: 11.5283\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 432us/step - loss: 11.5615\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 0s 426us/step - loss: 11.4366\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 402us/step - loss: 11.4073\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 432us/step - loss: 11.4181\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 11.2238\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 0s 525us/step - loss: 11.2793\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 506us/step - loss: 11.1979\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 583us/step - loss: 11.1616\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 477us/step - loss: 11.0807\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 0s 555us/step - loss: 11.0738\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 754us/step - loss: 11.0193\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 570us/step - loss: 11.0235\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 0s 596us/step - loss: 10.8720\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 10.8031\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 525us/step - loss: 10.8709\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 500us/step - loss: 10.8417\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 0s 481us/step - loss: 10.8166\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 530us/step - loss: 10.6233\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 504us/step - loss: 10.5991\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 459us/step - loss: 10.7297\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 0s 452us/step - loss: 10.4668\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 538us/step - loss: 10.7145\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 477us/step - loss: 10.5219\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 476us/step - loss: 10.5277\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 569us/step - loss: 10.4423\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 494us/step - loss: 10.3845\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 469us/step - loss: 10.3283\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 10.2508\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 461us/step - loss: 10.3339\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 449us/step - loss: 10.3451\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 10.2350\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 414us/step - loss: 10.2661\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 477us/step - loss: 10.0718\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 448us/step - loss: 10.1250\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 10.1983\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 478us/step - loss: 10.0608\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 431us/step - loss: 10.0486\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.9823\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 414us/step - loss: 10.0068\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 9.9335\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 392us/step - loss: 9.9209\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 414us/step - loss: 9.9452\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 362us/step - loss: 9.8553\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 460us/step - loss: 9.9858\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 518us/step - loss: 9.9013\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 438us/step - loss: 9.8010\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 9.7995\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 9.7790\n",
      "50/50 [==============================] - 2s 40ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 5s 10ms/step - loss: 600.2587\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 566.1274\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 496.0055\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 483us/step - loss: 384.4390\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 250.2294\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 134.3778\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 69.9551\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 45.6831\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 34.5374\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 27.9576\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 24.7396\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 22.8267\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 21.7671\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 20.7968\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 19.9953\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 19.2970\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 18.6149\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 18.0197\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 17.5880\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 16.8830\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 16.4916\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 15.9640\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 15.5229\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 15.2684\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 467us/step - loss: 14.8094\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 14.4360\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 14.1170\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 13.7460\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 13.4967\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 13.0976\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 12.7726\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 483us/step - loss: 12.4317\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 12.2093\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 483us/step - loss: 11.7223\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 11.4705\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 11.2849\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 10.9297\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 10.6357\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 10.2970\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 9.9846\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 9.7339\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 9.4496\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 9.2107\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.9866\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 8.8600\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 8.6452\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.4997\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 8.3553\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.2227\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.1176\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 7.9811\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 7.8795\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 7.8023\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 7.6751\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 7.6404\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 7.5102\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 492us/step - loss: 7.3985\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 7.3650\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 7.2587\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 7.2151\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 485us/step - loss: 7.1543\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 7.1372\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 6.9978\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 7.0036\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 6.9440\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 6.8975\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 6.8473\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 6.7642\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 6.7257\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 6.7093\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 6.6974\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 0s 475us/step - loss: 6.6410\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 6.5577\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 518us/step - loss: 6.5695\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 6.4587\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 6.4343\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 6.4611\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 6.3508\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 6.3324\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 6.3107\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 6.2791\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 6.2932\n",
      "Epoch 83/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 0s 491us/step - loss: 6.2246\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 6.1859\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 6.1591\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 6.1418\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 6.1538\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 6.1090\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 6.0245\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 6.0835\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 6.0436\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 5.9815\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 5.9762\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 5.9896\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 5.9572\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 5.9142\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 5.9108\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 5.8487\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 5.8782\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 5.8641\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 5.8354\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 5.8003\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 5.7154\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 5.8199\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 5.7327\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 5.7314\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 5.7172\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 5.6900\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 5.6906\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 5.6834\n",
      "50/50 [==============================] - 2s 41ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 5s 11ms/step - loss: 624.8165\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 569.9426\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 452.6482\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 290.3469\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 143.8501\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 78.1590\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 52.8180\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 40.9428\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 35.5821\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 33.0709\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 30.9321\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 29.5499\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 28.2134\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 26.9328\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 25.8050\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 24.7273\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 23.9476\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 22.9174\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 21.9592\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 21.2554\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 20.5338\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 19.8008\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 19.2078\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 18.5473\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 17.9631\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 17.3315\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 16.8260\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 16.3431\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 15.9848\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 15.3529\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 15.1467\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 14.7885\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 14.2967\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 14.2259\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 13.9571\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 13.6037\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 13.4063\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 13.1933\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 13.1217\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 12.8604\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 12.5823\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 12.4270\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 12.0854\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 12.1525\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 11.9305\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 11.7151\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 11.5534\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 11.5324\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 11.3285\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 11.1833\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 11.1882\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 526us/step - loss: 11.0146\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 10.8331\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 10.8442\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 10.7325\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 457us/step - loss: 10.5306\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 466us/step - loss: 10.6206\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 412us/step - loss: 10.4645\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 10.3230\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 10.2078\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 10.3224\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 10.2143\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 9.9749\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 10.0615\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 9.9380\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 9.7409\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 9.9023\n",
      "Epoch 68/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 0s 456us/step - loss: 9.7404\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 440us/step - loss: 9.7700\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 9.5221\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 9.6766\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 9.5969\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 9.5242\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 9.4401\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.4400\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.4271\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 9.3103\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 9.2709\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.2884\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 9.2084\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 9.1863\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 9.0943\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 8.9726\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 9.0406\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 9.0408\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 412us/step - loss: 8.9800\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 9.0620\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 8.8821\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 8.8075\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 8.9353\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 8.7650\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 8.7444\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 8.7606\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 8.7728\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.6540\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 8.5889\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 518us/step - loss: 8.4830\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 570us/step - loss: 8.5839\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 553us/step - loss: 8.6013\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 8.5788\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 580us/step - loss: 8.5532\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 8.6146\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 570us/step - loss: 8.5024\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.4176\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 8.3104\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 553us/step - loss: 8.4115\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.4495\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 8.3777\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 588us/step - loss: 8.3789\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 8.3087\n",
      "50/50 [==============================] - 2s 43ms/step\n",
      "Epoch 1/110\n",
      "456/456 [==============================] - 5s 10ms/step - loss: 610.6768\n",
      "Epoch 2/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 578.2217\n",
      "Epoch 3/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 496.1435\n",
      "Epoch 4/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 364.9874\n",
      "Epoch 5/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 214.7922\n",
      "Epoch 6/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 111.6121\n",
      "Epoch 7/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 71.9834\n",
      "Epoch 8/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 53.8844\n",
      "Epoch 9/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 42.3279\n",
      "Epoch 10/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 35.3360\n",
      "Epoch 11/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 31.9216\n",
      "Epoch 12/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 30.1540\n",
      "Epoch 13/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 28.4870\n",
      "Epoch 14/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 28.1450\n",
      "Epoch 15/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 27.1745\n",
      "Epoch 16/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 26.1227\n",
      "Epoch 17/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 25.5857\n",
      "Epoch 18/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 24.7606\n",
      "Epoch 19/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 24.3389\n",
      "Epoch 20/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 23.7848\n",
      "Epoch 21/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 23.1434\n",
      "Epoch 22/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 22.6608\n",
      "Epoch 23/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 22.0521\n",
      "Epoch 24/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 21.8564\n",
      "Epoch 25/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 21.2373\n",
      "Epoch 26/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 20.9503\n",
      "Epoch 27/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 20.5008\n",
      "Epoch 28/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 20.0139\n",
      "Epoch 29/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 19.5851\n",
      "Epoch 30/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 19.2016\n",
      "Epoch 31/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 18.8569\n",
      "Epoch 32/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 18.5330\n",
      "Epoch 33/110\n",
      "456/456 [==============================] - 0s 492us/step - loss: 18.2158\n",
      "Epoch 34/110\n",
      "456/456 [==============================] - 0s 484us/step - loss: 18.0176\n",
      "Epoch 35/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 17.6034\n",
      "Epoch 36/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 17.2835\n",
      "Epoch 37/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 17.0081\n",
      "Epoch 38/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 16.8929\n",
      "Epoch 39/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 16.5211\n",
      "Epoch 40/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 16.2031\n",
      "Epoch 41/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 15.9970\n",
      "Epoch 42/110\n",
      "456/456 [==============================] - 0s 483us/step - loss: 15.7600\n",
      "Epoch 43/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 15.5075\n",
      "Epoch 44/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 15.2986\n",
      "Epoch 45/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 15.1282\n",
      "Epoch 46/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 14.8117\n",
      "Epoch 47/110\n",
      "456/456 [==============================] - 0s 474us/step - loss: 14.7778\n",
      "Epoch 48/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 14.4830\n",
      "Epoch 49/110\n",
      "456/456 [==============================] - 0s 483us/step - loss: 14.2931\n",
      "Epoch 50/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 14.1935\n",
      "Epoch 51/110\n",
      "456/456 [==============================] - 0s 482us/step - loss: 14.1188\n",
      "Epoch 52/110\n",
      "456/456 [==============================] - 0s 491us/step - loss: 13.9850\n",
      "Epoch 53/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 13.8460\n",
      "Epoch 54/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 13.6117\n",
      "Epoch 55/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 13.6160\n",
      "Epoch 56/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 13.4652\n",
      "Epoch 57/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 13.1671\n",
      "Epoch 58/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 13.1680\n",
      "Epoch 59/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 12.7986\n",
      "Epoch 60/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 12.9869\n",
      "Epoch 61/110\n",
      "456/456 [==============================] - 0s 421us/step - loss: 12.7590\n",
      "Epoch 62/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 12.6133\n",
      "Epoch 63/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 12.5602\n",
      "Epoch 64/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 12.3720\n",
      "Epoch 65/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 12.3082\n",
      "Epoch 66/110\n",
      "456/456 [==============================] - 0s 500us/step - loss: 12.3203\n",
      "Epoch 67/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 12.1594\n",
      "Epoch 68/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 12.0551\n",
      "Epoch 69/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 11.9845\n",
      "Epoch 70/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 11.9498\n",
      "Epoch 71/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 11.8833\n",
      "Epoch 72/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 11.6501\n",
      "Epoch 73/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 11.7910\n",
      "Epoch 74/110\n",
      "456/456 [==============================] - 0s 440us/step - loss: 11.5833\n",
      "Epoch 75/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 11.4664\n",
      "Epoch 76/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 11.4237\n",
      "Epoch 77/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 11.4195\n",
      "Epoch 78/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 11.3078\n",
      "Epoch 79/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 11.2185\n",
      "Epoch 80/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 11.1361\n",
      "Epoch 81/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 11.0772\n",
      "Epoch 82/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 11.0397\n",
      "Epoch 83/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.9830\n",
      "Epoch 84/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 10.8054\n",
      "Epoch 85/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.8137\n",
      "Epoch 86/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 10.7842\n",
      "Epoch 87/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 10.6836\n",
      "Epoch 88/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.7061\n",
      "Epoch 89/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.5834\n",
      "Epoch 90/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 10.5529\n",
      "Epoch 91/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 10.5225\n",
      "Epoch 92/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 10.4508\n",
      "Epoch 93/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.4101\n",
      "Epoch 94/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 10.4143\n",
      "Epoch 95/110\n",
      "456/456 [==============================] - 0s 456us/step - loss: 10.3379\n",
      "Epoch 96/110\n",
      "456/456 [==============================] - 0s 447us/step - loss: 10.4084\n",
      "Epoch 97/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.1679\n",
      "Epoch 98/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.1655\n",
      "Epoch 99/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.1581\n",
      "Epoch 100/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 10.1097\n",
      "Epoch 101/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.0342\n",
      "Epoch 102/110\n",
      "456/456 [==============================] - 0s 430us/step - loss: 9.9885\n",
      "Epoch 103/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 10.0018\n",
      "Epoch 104/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.9346\n",
      "Epoch 105/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.9461\n",
      "Epoch 106/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.8319\n",
      "Epoch 107/110\n",
      "456/456 [==============================] - 0s 465us/step - loss: 9.8853\n",
      "Epoch 108/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.8539\n",
      "Epoch 109/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.7162\n",
      "Epoch 110/110\n",
      "456/456 [==============================] - 0s 439us/step - loss: 9.6351\n",
      "50/50 [==============================] - 2s 40ms/step\n",
      "Larger: -21.19 (24.66) MSE\n"
     ]
    }
   ],
   "source": [
    "# model1 with rmsprop with 110 epochs, and second layer of 7 neurons, changing batch size to 7\n",
    "\n",
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(7, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=model1, epochs=110, batch_size=7, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model with rmsprop, 110 epochs, and two layers of 26 and 7 neurons produced the most efficient result so we will be using that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. Rewriting the code using the Keras Functional API\n",
    "Now rewrite the code that you have written so far using the Keras Sequential API in Kearas Functional API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.33 (24.75) MSE\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    inputs = keras.Input(shape = X[1].shape)\n",
    "    x_1 = layers.Dense(26, activation = 'relu', kernel_initializer='normal')(inputs)\n",
    "    x_2 = layers.Dense(7, activation = 'relu', kernel_initializer='normal')(x_1)\n",
    "    outputs = layers.Dense(1, kernel_initializer='normal')(x_2)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['mean_squared_error'])\n",
    "    return model\n",
    "  \n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=create_model, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8. Rewriting the code by doing Model Subclassing\n",
    "Now rewrite the code that you have written so far using the Keras Model Subclassing as mentioned in the Chollet April 9, 2018 presentation.\n",
    "\n",
    "Reference:\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "Please note you will have to use TensorFlow 1.7+ with built-in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.33 (24.75) MSE\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(26, activation = 'relu', kernel_initializer = 'normal')\n",
    "        self.dense2 = layers.Dense(7, activation = 'relu', kernel_initializer = 'normal')\n",
    "        self.dense3 = layers.Dense(1, kernel_initializer = 'normal')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x_1 = self.dense1(inputs)\n",
    "        x_2 = self.dense2(x_1)\n",
    "        return self.dense3(x_2)\n",
    "    \n",
    "  \n",
    "def create_model():\n",
    "  model = MyModel()\n",
    "  model.compile(optimizer = 'rmsprop',loss = 'mean_squared_error',metrics=['mean_squared_error'] )\n",
    "  return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=create_model, epochs=110, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9. Rewriting the code without using scikit-learn\n",
    "Once you have written the model in all three API style you are required to do k-fold cross validation without using scikit-learn library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "data = dataframe.values\n",
    "np.random.shuffle(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 0:13]\n",
    "Y = data[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Processing field # 0\n",
      "50/50 [==============================] - 0s 7ms/step\n",
      "Processing field # 1\n",
      "50/50 [==============================] - 0s 7ms/step\n",
      "Processing field # 2\n",
      "50/50 [==============================] - 0s 8ms/step\n",
      "Processing field # 3\n",
      "50/50 [==============================] - 0s 8ms/step\n",
      "Processing field # 4\n",
      "50/50 [==============================] - 0s 8ms/step\n",
      "Processing field # 5\n",
      "50/50 [==============================] - 0s 9ms/step\n",
      "Processing field # 6\n",
      "50/50 [==============================] - 1s 10ms/step\n",
      "Processing field # 7\n",
      "50/50 [==============================] - 1s 10ms/step\n",
      "Processing field # 8\n",
      "50/50 [==============================] - 1s 10ms/step\n",
      "Processing field # 9\n",
      "50/50 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "def model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(26, activation = 'relu',kernel_initializer = 'normal', input_shape = (X.shape[1],)))\n",
    "    model.add(layers.Dense(7, activation = 'relu',kernel_initializer = 'normal'))\n",
    "    model.add(layers.Dense(1, kernel_initializer = 'normal',))\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "k = 10\n",
    "num_val_samples = len(X) // k #integer division\n",
    "print(num_val_samples)\n",
    "num_epochs = 110\n",
    "results = []\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Processing field #\", i)\n",
    "    #prepairing the validation data:data from partition K\n",
    "    val_data = X[i*num_val_samples:(i+1)*num_val_samples]      \n",
    "    val_targets = Y[i*num_val_samples:(i+1)*num_val_samples]\n",
    "    #prepairing training data from all other partitions\n",
    "    partial_train_data = np.concatenate([\n",
    "        X[:i*num_val_samples],\n",
    "        X[(i+1)*num_val_samples:]\n",
    "    ], axis = 0)\n",
    "    partial_train_target = np.concatenate([\n",
    "        Y[:i*num_val_samples],\n",
    "        Y[(i+1)*num_val_samples:]\n",
    "    ],axis = 0)\n",
    "    partial_train_data_mean = partial_train_data.mean(axis = 0)\n",
    "    partial_train_data_std = partial_train_data.std(axis = 0)\n",
    "    partial_train_data = (partial_train_data - partial_train_data_mean)/partial_train_data_std\n",
    "    val_data = (val_data - partial_train_data_mean)/partial_train_data_std\n",
    "   \n",
    "    model = model1()\n",
    "    model.fit(partial_train_data, \n",
    "              partial_train_target,\n",
    "              epochs = num_epochs, \n",
    "              batch_size = 5, verbose = 0)\n",
    "    results.append(model.evaluate(val_data, val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mean_squared_error']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.916297643661498"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = []\n",
    "for result in results:\n",
    "    mse.append(result[1])\n",
    "mse = np.asarray(mse)\n",
    "overall_MSE = mse.mean()\n",
    "overall_MSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
